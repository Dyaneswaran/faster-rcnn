{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone of the Network\n",
    "  > RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing ResNet50 Source code\n",
    "(From Actual Keras Implementation of ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, \\\n",
    "    AveragePooling2D, TimeDistributed, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    shortcut = Convolution2D(nb_filter3, (1, 1), strides=strides, name=conv_name_base + '1', trainable=trainable)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_base(input_tensor=None, trainable=False):\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (3, None, None)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "        \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            print(\"Not Keras tensor\")\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            print(\"Keras tensor\")\n",
    "\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    print(x.shape)\n",
    "    x = Convolution2D(64, (7, 7), strides=(2, 2), name='conv1', trainable = trainable)(x)\n",
    "    print(x.shape)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    print(x.shape)\n",
    "    x = Activation('relu')(x)\n",
    "    print(x.shape)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', trainable = trainable)\n",
    "    \n",
    "    print(x.shape)\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', trainable = trainable)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Ratio = $1024/64$ = $16$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding Boxes, Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 1024, 1024\n",
    "subsampling_ratio = 16\n",
    "\n",
    "img = np.zeros((height, width, 3))\n",
    "\n",
    "### Bounding Box Format ####\n",
    "# Origin - top-left corner.\n",
    "# [xmin, ymin, xmaxm, ymax]\n",
    "############################\n",
    "\n",
    "bbox = np.asarray([[20, 40, 400, 100], [400, 800, 800, 1000]], dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Anchor Boxes of Different Scales & Aspect Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1204 23:09:05.038197 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1204 23:09:05.044710 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1204 23:09:05.090514 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1204 23:09:05.091513 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1204 23:09:05.092849 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Keras tensor\n",
      "(1, 1030, 1030, 3)\n",
      "(1, 512, 512, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 23:09:11.587612 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1204 23:09:11.803311 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 64)\n",
      "(1, 512, 512, 64)\n",
      "(1, 255, 255, 64)\n",
      "(1, 255, 255, 256)\n",
      "(1, 255, 255, 256)\n",
      "(1, 255, 255, 256)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "feature_map = nn_base(K.expand_dims(K.variable(img), axis=0))\n",
    "print(feature_map.shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n"
     ]
    }
   ],
   "source": [
    "scales = [8, 16, 32]\n",
    "ratios = [0.5, 1, 2]\n",
    "\n",
    "k = len(scales) * len(ratios)\n",
    "feature_map_size = feature_map.shape[1]\n",
    "\n",
    "anchors = np.zeros((k * feature_map_size * feature_map_size, 4))\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchor Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(subsampling_ratio/2, width, subsampling_ratio, dtype = np.int32)\n",
    "\n",
    "anchor_centres = np.zeros((anchors.shape[0], 2))\n",
    "\n",
    "anchor_centres[:, 0] = np.tile(np.repeat(x, k), feature_map_size) #XCOORDINATES\n",
    "anchor_centres[:, 1] = np.repeat(x, k * feature_map_size) #YCOORDINATES\n",
    "\n",
    "\n",
    "##### ANCHOR CENTRES ######\n",
    "# A1,1, A1,2, A1,3 .... A1,K, A2,1, A2,2, ... A2,K, ........ AFEATUREMAP_SIZE*FEATUREMAP_SIZE,K \n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchor Box Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 5 6 7 8 9 9]\n"
     ]
    }
   ],
   "source": [
    "## Checking Numpy Indexing\n",
    "\n",
    "i = np.array([1,2,3])\n",
    "x = np.array([1,2,4,5,5,6,7,8,9,9])\n",
    "y = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "x[i] = y[i]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_box_no = 0\n",
    "for scale in scales:\n",
    "    for ratio in ratios:\n",
    "        w = subsampling_ratio * scale * np.sqrt(ratio)\n",
    "        h = subsampling_ratio * scale * (1/np.sqrt(ratio))\n",
    "        \n",
    "        ### ANCHOR BOX COORDINATES WITH SCALEi, RATIOj###\n",
    "        anchor_coords = np.arange(start_box_no, anchor_centres.shape[0], step = k)\n",
    "        \n",
    "        anchors[anchor_coords, 0] = anchor_centres[anchor_coords, 0] - w/2 # XMIN\n",
    "        anchors[anchor_coords, 2] = anchor_centres[anchor_coords, 0] + w/2 # YMIN\n",
    "        anchors[anchor_coords, 1] = anchor_centres[anchor_coords, 1] - h/2 # XMAX\n",
    "        anchors[anchor_coords, 3] = anchor_centres[anchor_coords, 1] + h/2 # YMAX\n",
    "        \n",
    "        start_box_no += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
      " [ -56.          -56.           72.           72.        ]\n",
      " [ -82.50966799  -37.254834     98.50966799   53.254834  ]\n",
      " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
      " [-120.         -120.          136.          136.        ]\n",
      " [-173.01933598  -82.50966799  189.01933598   98.50966799]\n",
      " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
      " [-248.         -248.          264.          264.        ]\n",
      " [-354.03867197 -173.01933598  370.03867197  189.01933598]]\n"
     ]
    }
   ],
   "source": [
    "print(anchors[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Labels to Anchor Boxes\n",
    "\n",
    "Positive Labels\n",
    "\n",
    "> 1. For a Ground Truth, the anchor with the max IOU.\n",
    "> 2. For an Anchor Box, if it has IOU > 0.7 with any of the ground truths.\n",
    "\n",
    "Negative Labels\n",
    "\n",
    "> If the anchor box has IOU < 0.3 with every ground truth, then its a negative label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(a, b):\n",
    "    \n",
    "    (xa1, ya1, xa2, ya2) = a\n",
    "    (xb1, yb1, xb2, yb2) = b\n",
    "    \n",
    "    ## CALCULATE INTERSECTION, UNION.\n",
    "    \n",
    "    x1 = max(xa1, xb1)\n",
    "    y1 = max(ya1, yb1)\n",
    "    x2 = min(xa2, xb2)\n",
    "    y2 = min(ya2, yb2)\n",
    "    \n",
    "    ## IF INTERSECTION IS ONE POINT, THEN AREA IS ONE PIXEL.\n",
    "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "    area1 = (xa2 - xa1 + 1) * (ya2 - ya1 + 1)\n",
    "    area2 = (xb2 - xb1 + 1) * (yb2 - yb1 + 1)\n",
    "    \n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection/union\n",
    "    \n",
    "    ## UNION = A + B - (A^B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5451683189282869\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "a = [20, 30, 400, 500]\n",
    "b = [30, 40, 300, 400]\n",
    "\n",
    "print(IoU(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out Anchors whose Coordinates lie outside the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[1 2 3 4]\n",
      " [5 0 0 0]\n",
      " [9 8 7 0]]\n",
      "[[1 2 3 4]\n",
      " [9 8 7 0]]\n",
      "[[1 2 3 4]]\n",
      "[ True False  True]\n",
      "[[1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "temp = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 0, 0, 0],\n",
    "    [9, 8, 7, 0]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "## FIRST COLUMN FILTER\n",
    "print(temp[temp[:,0] > 0])\n",
    "temp = temp[temp[:,0] > 0]\n",
    "\n",
    "## SECOND COLUMN FILTER\n",
    "print(temp[temp[:,1] > 0])\n",
    "temp = temp[temp[:,1] > 0]\n",
    "\n",
    "## FOURTH COLUMN FILTER\n",
    "print(temp[temp[:,3] > 0])\n",
    "temp = temp[temp[:,3] > 0]\n",
    "\n",
    "\n",
    "\n",
    "## APPLYING ALL FILTERS TOGETHER\n",
    "temp = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 0, 0, 0],\n",
    "    [9, 8, 7, 0]\n",
    "])\n",
    "\n",
    "print((temp[:,0] > 0) & (temp[:,1] > 0))\n",
    "temp = temp[(temp[:,0] > 0) & (temp[:,1] > 0) & (temp[:,3] > 0)]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n",
      "(18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "temp = anchors\n",
    "print(temp.shape)\n",
    "temp = temp[(temp[:,0] >= 0) & (temp[:,1] >= 0) & (temp[:,2] <= width) & (temp[:,3] <= height)]\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18376\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "## USING NUMPY ##\n",
    "\n",
    "# BRACKETS IMPORTANT #\n",
    "index_inside = np.where(\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    )[0]\n",
    "\n",
    "print(len(index_inside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Valid Anchors: (18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## USING NUMPY INDEXING ##\n",
    "\n",
    "filtered_anchors = anchors[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "]\n",
    "\n",
    "print(\"No. of Valid Anchors: {}\".format(filtered_anchors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is required to label anchor boxes ??\n",
    "> - For each ground truth, find all anchors that have IOU equal to the max IOU. (directly can be labelled positive.)\n",
    "> - Find all anchors that have max IOU with respect to a groud truth. (positive > 0.7, negative < 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18376)\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "ious = np.zeros((bbox.shape[0], filtered_anchors.shape[0]), dtype = np.float64)\n",
    "\n",
    "for i,a in enumerate(bbox):\n",
    "    for j,b in enumerate(filtered_anchors):\n",
    "        ious[i,j] = IoU(a, b)\n",
    "\n",
    "print(ious.shape)\n",
    "print(ious[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[    1 17815]\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.00283193 0.         0.        ]\n",
      "[0.38560272 0.81984166]\n",
      "(15,)\n",
      "(36366,)\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "\n",
    "print(np.argmax(ious, axis=0))\n",
    "print(np.argmax(ious, axis=1))\n",
    "\n",
    "best_groundtruth_for_each_anchor = np.argmax(ious, axis=0)\n",
    "best_anchor_for_each_groundtruth = np.argmax(ious, axis=1)\n",
    "\n",
    "\n",
    "print(ious.max(axis = 0))\n",
    "print(ious.max(axis = 1))\n",
    "\n",
    "\n",
    "\n",
    "## CALCUALTING NO OF ANCHORS WITH IOU > 0.7 ##\n",
    "\n",
    "print(ious[ious > 0.7].shape)\n",
    "print(ious[ious < 0.3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 7]\n",
      "[5 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "a = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 5, 6, 7],\n",
    "])\n",
    "\n",
    "## MAX ALONG AXIS 1 ##\n",
    "x = a[np.arange(a.shape[0]),a.argmax(axis = 1)]\n",
    "print(x)\n",
    "\n",
    "## MAX ALONG AXIS 0 ##\n",
    "x = a[a.argmax(axis = 0), np.arange(a.shape[1])]\n",
    "print(x)\n",
    "\n",
    "\n",
    "### BELOW METHOD NOT WORKING OUT ###\n",
    "### GETTING BROADCASTED UNNECESSARILY ###\n",
    "\n",
    "# print(a.argmax(axis = 0))\n",
    "# print(a[[1,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1 17815]\n",
      "[0.38560272 0.81984166]\n",
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17815 17819 17823]\n"
     ]
    }
   ],
   "source": [
    "### CONDITION 1 ###\n",
    "\n",
    "'''\n",
    "What do we need??\n",
    "For each groundtruth, we need anchors with the max IOU.\n",
    "'''\n",
    "\n",
    "## BEST ANCHOR FOR EACH GROUND TRUTH ##\n",
    "gt_best_arg_anchors = ious.argmax(axis = 1)\n",
    "\n",
    "## BEST ANCHOR IOUS ##\n",
    "gt_best_anchors_ious = ious.max(axis = 1)\n",
    "\n",
    "## ANCHORS THAT HAVE IOU EQUAL TO BEST ANCHOR IOU ##\n",
    "gt_best_anchors = np.where(np.isin(ious, gt_best_anchors_ious))[1]\n",
    "\n",
    "'''\n",
    "#### THIS IS NOT WORKING FOR SOME REASON ####\n",
    "## ious[ious == gt_best_anchors_ious] ##\n",
    "#############################################\n",
    "\n",
    "### FOR LOOP METHOD OF OBTAINING ANCHORS EQUAL TO MAX IOU ###\n",
    "### NOT ADVISABLE! USE NUMPY!! ###\n",
    "\n",
    "for i in range(ious.shape[0]):\n",
    "    print(ious[i].shape, gt_best_anchors_ious.shape)\n",
    "    print(np.where(ious[i] == gt_best_anchors_ious[i]))\n",
    "\n",
    "'''\n",
    "\n",
    "print(gt_best_arg_anchors)\n",
    "print(gt_best_anchors_ious)\n",
    "print(gt_best_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.00283193 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "### CONDITION 2 ###\n",
    "\n",
    "\"\"\"\n",
    "What do we need?\n",
    "For each anchor, find for which ground truth it has highest IOU.\n",
    "\"\"\"\n",
    "\n",
    "anchor_best_arg_gt = ious.argmax(axis = 0)\n",
    "anchor_best_gt_ious = ious.max(axis = 0)\n",
    "\n",
    "\n",
    "### Here we dont have to find which ground truth box the respective anchor has hihgest IOU. ###\n",
    "### Reference Paper says so. ###\n",
    "\n",
    "print(anchor_best_arg_gt)\n",
    "print(anchor_best_gt_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Labels\n",
    "\n",
    "Label Values\n",
    "\n",
    "> - -1 = ignore label\n",
    "> - 1 = positive label\n",
    "> - 0 = negative label\n",
    "\n",
    "\n",
    "IOU Thresholds\n",
    "\n",
    "> - Positive Label = > 0.7\n",
    "> - Negative Label = < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.full((filtered_anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "positive_threshold = 0.7\n",
    "negative_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POSITIVE LABELS ###\n",
    "## CONDITION 1\n",
    "\n",
    "labels[gt_best_anchors] = 1\n",
    "\n",
    "## CONDITION 2\n",
    "\n",
    "labels[anchor_best_gt_ious >= positive_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NGEATIVE LABELS ###\n",
    "\n",
    "labels[anchor_best_gt_ious < negative_threshold] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the RPN\n",
    "> #### Sampling\n",
    "> #### Parameterizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling\n",
    "- Each minibatch comes from one single image.\n",
    "- From that image, we will use 256 anchors as sample.\n",
    "- In each sample, the ratio of positive to negative anchors is $1:1$.\n",
    "- If this is not so, we will make it so by disabling certain anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Ideal Positive Samples: 128.0.\n",
      "No. of Ideal Negative Samples: 128.0.\n"
     ]
    }
   ],
   "source": [
    "sample_size = 256\n",
    "pos_ratio = 0.5\n",
    "\n",
    "pos_size = sample_size * pos_ratio\n",
    "neg_size = sample_size - pos_size\n",
    "\n",
    "\n",
    "print(\"No. of Ideal Positive Samples: {}.\".format(pos_size))\n",
    "print(\"No. of Ideal Negative Samples: {}.\".format(neg_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Positive Labels: 39\n",
      "No. of Negative Labels: 17990\n",
      "No. of Disabled Labels: 347\n"
     ]
    }
   ],
   "source": [
    "pos_labels = labels[labels == 1]\n",
    "neg_labels = labels[labels == 0]\n",
    "disabled_labels = labels[labels == -1]\n",
    "\n",
    "\n",
    "print(\"No. of Positive Labels: {}\".format(len(pos_labels)))\n",
    "print(\"No. of Negative Labels: {}\".format(len(neg_labels)))\n",
    "print(\"No. of Disabled Labels: {}\".format(len(disabled_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17583 17588 17593 17598 17603 17807 17811 17815 17819 17823 17827 17831\n",
      " 18023 18027 18031]\n",
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17583 17588 17593 17598 17603 17807 17811 17815 17819 17823 17827 17831\n",
      " 18023 18027 18031]\n"
     ]
    }
   ],
   "source": [
    "## SHORT ROUTE ##\n",
    "print(np.where(labels == 1)[0])\n",
    "\n",
    "## LONG ROUTE ##\n",
    "print(np.where((labels == 1) == True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISABLING ANCHORS ###\n",
    "\n",
    "if len(pos_labels) > pos_size:\n",
    "    pos_indices = np.where(labels == 1)[0]\n",
    "    disabled_indices = np.random.choice(pos_indices, len(pos_labels) - pos_size, replace = False)\n",
    "    labels[disabled_indices] = -1\n",
    "\n",
    "## UPDATE NO. OF POSITIVE LABELS ##\n",
    "pos_size = len(pos_labels)\n",
    "\n",
    "\n",
    "if len(neg_labels) > sample_size - pos_size:\n",
    "    neg_indices = np.where(labels == 0)[0]\n",
    "    disabled_indices = np.random.choice(neg_indices, len(neg_indices) - pos_size, replace = False)\n",
    "    labels[disabled_indices] = -1\n",
    "\n",
    "## UPDATE NO. OF NEGATIVE LABELS ##\n",
    "neg_size = pos_size\n",
    "\n",
    "\n",
    "## RUN PREVIOUS CELL TO SEE THAT NO OF -VE LABELS == +VE LABELS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameterizing Anchor Box Coordiantes\n",
    "\n",
    "> $x' = (x - xa) / wa $ \\\n",
    "$y' = (y - ya) / ha $ \\\n",
    "$w' = log(w/wa) $ \\\n",
    "$h' = log(h/ha) $\n",
    "\n",
    "From this we can see that we need,\n",
    "\n",
    "- groundtruth_box = \\[xc, yc, w, h] for which that anchor has max IOU.\n",
    "\n",
    "\n",
    "We need to format the anchor targets in the same form before parameterizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " ...\n",
      " [ 400  800  800 1000]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]]\n"
     ]
    }
   ],
   "source": [
    "## TAKING ADVANTAGE OF NUMPY BROADCASTING TO GENERATE GT BOXES FOR EACH ANHOR ##\n",
    "\n",
    "anchor_best_gt_boxes_coords = bbox[anchor_best_arg_gt]\n",
    "print(anchor_best_gt_boxes_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104. 120. 136. ... 888. 904. 920.]\n",
      "[ 56.  56.  56. ... 968. 968. 968.]\n",
      "[181.01933598 181.01933598 181.01933598 ... 181.01933598 181.01933598\n",
      " 181.01933598]\n",
      "[90.50966799 90.50966799 90.50966799 ... 90.50966799 90.50966799\n",
      " 90.50966799]\n",
      "(18376,)\n"
     ]
    }
   ],
   "source": [
    "## CALCULATING ANCHOR BOX XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "anchor_w = filtered_anchors[:,2] - filtered_anchors[:,0]\n",
    "anchor_h = filtered_anchors[:,3] - filtered_anchors[:,1]\n",
    "\n",
    "anchor_x_c = filtered_anchors[:,0] + 0.5 * anchor_w\n",
    "anchor_y_c = filtered_anchors[:,1] + 0.5 * anchor_h\n",
    "\n",
    "print(anchor_x_c)\n",
    "print(anchor_y_c)\n",
    "print(anchor_w)\n",
    "print(anchor_h)\n",
    "\n",
    "print(anchor_x_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210. 210. 210. ... 600. 210. 210.]\n",
      "[ 70.  70.  70. ... 900.  70.  70.]\n",
      "[380 380 380 ... 400 380 380]\n",
      "[ 60  60  60 ... 200  60  60]\n",
      "(18376,)\n"
     ]
    }
   ],
   "source": [
    "## CALCULATING GROUND TRUTH XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "gt_w = anchor_best_gt_boxes_coords[:,2] - anchor_best_gt_boxes_coords[:,0]\n",
    "gt_h = anchor_best_gt_boxes_coords[:,3] - anchor_best_gt_boxes_coords[:,1]\n",
    "\n",
    "gt_x_c = anchor_best_gt_boxes_coords[:,0] + 0.5 * gt_w\n",
    "gt_y_c = anchor_best_gt_boxes_coords[:,1] + 0.5 * gt_h\n",
    "\n",
    "print(gt_x_c)\n",
    "print(gt_y_c)\n",
    "print(gt_w)\n",
    "print(gt_h)\n",
    "\n",
    "\n",
    "print(gt_x_c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5855728   0.49718446  0.40879611 ... -1.59099026 -3.83384458\n",
      " -3.92223293]\n",
      "[ 0.15467961  0.15467961  0.15467961 ... -0.75130096 -9.92159202\n",
      " -9.92159202]\n",
      "[0.7415674  0.7415674  0.7415674  ... 0.79286069 0.7415674  0.7415674 ]\n",
      "[-0.41111211 -0.41111211 -0.41111211 ...  0.79286069 -0.41111211\n",
      " -0.41111211]\n"
     ]
    }
   ],
   "source": [
    "## APPLYING ABOVE FORMULA ##\n",
    "\n",
    "t_x = (gt_x_c - anchor_x_c)/anchor_w\n",
    "t_y = (gt_y_c - anchor_y_c)/anchor_h\n",
    "t_w = np.log(gt_w/anchor_w)\n",
    "t_h = np.log(gt_h/anchor_h)\n",
    "\n",
    "print(t_x)\n",
    "print(t_y)\n",
    "print(t_w)\n",
    "print(t_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5855728   0.15467961  0.7415674  -0.41111211]\n",
      " [ 0.49718446  0.15467961  0.7415674  -0.41111211]\n",
      " [ 0.40879611  0.15467961  0.7415674  -0.41111211]\n",
      " ...\n",
      " [-1.59099026 -0.75130096  0.79286069  0.79286069]\n",
      " [-3.83384458 -9.92159202  0.7415674  -0.41111211]\n",
      " [-3.92223293 -9.92159202  0.7415674  -0.41111211]]\n",
      "(18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## CONVERTING TO [XC, YC, W, H] FORMAT ##\n",
    "\n",
    "\n",
    "t_anchors = np.zeros((filtered_anchors.shape[0], 4))\n",
    "t_anchors[:,0] = t_x\n",
    "t_anchors[:,1] = t_y\n",
    "t_anchors[:,2] = t_w\n",
    "t_anchors[:,3] = t_h\n",
    "\n",
    "\n",
    "print(t_anchors)\n",
    "print(t_anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n",
      "[False False False ... False False False]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. We have calculated the anchors for only valid locations.\n",
    "2. We need to do it for invalid locations as well.\n",
    "\n",
    "And pass the whole thing to the RPN.\n",
    "These are the regression targets.\n",
    "'''\n",
    "\n",
    "anchor_targets = np.zeros((anchors.shape[0], 4))\n",
    "print(anchor_targets.shape)\n",
    "\n",
    "anchor_targets[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "] = t_anchors\n",
    "\n",
    "print( (anchors[:, 0] >= 0) & (anchors[:, 1] >= 0) & (anchors[:, 2] <= width) & (anchors[:, 3] <= height))\n",
    "print(anchor_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n",
      "(39,)\n",
      "(39,)\n",
      "(36786,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We need to prepare the anchor labels.\n",
    "These are the classification targets.\n",
    "'''\n",
    "\n",
    "anchor_labels = np.full((anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "anchor_labels[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "] = labels\n",
    "\n",
    "print(anchor_labels)\n",
    "print(anchor_labels[anchor_labels == 1].shape)\n",
    "print(anchor_labels[anchor_labels == 0].shape)\n",
    "print(anchor_labels[anchor_labels == -1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Architecture\n",
    "\n",
    "> Sliding a network over the feature map.\n",
    "> Use a Conv2D for regression & classification.\n",
    "\n",
    "- Regression No. of Output Channels: 4 * k\n",
    "- Classification No. of Output Channels: k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn(base_layers,num_anchors):\n",
    "    x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "    \n",
    "    x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "    x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
    "    \n",
    "    x_class = Reshape((-1, 1))(x_class)\n",
    "    x_regr = Reshape((-1, 4))(x_regr)\n",
    "    \n",
    "    return [x_class, x_regr, base_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_1/Reshape:0' shape=(1, 36864, 1) dtype=float32>, <tf.Tensor 'reshape_2/Reshape:0' shape=(1, 36864, 4) dtype=float32>, <tf.Tensor 'activation_40/Relu:0' shape=(1, 64, 64, 1024) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(rpn(feature_map, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_scores, pred_reg_scores, base_layers = rpn(feature_map, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_class_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 36864, 1)\n",
      "(1, 36864, 4)\n"
     ]
    }
   ],
   "source": [
    "#### RESHAPING REGRESSION OUTPUT TO [NO_ANCHORS,X,Y,W,H] ####\n",
    "#### RESHAPING CLASSIFICATION OUTPUT TO [NO_ANCHORS, OBJECTNESS_SCORE]\n",
    "\n",
    "print(pred_class_scores.shape)\n",
    "# print(K.reshape(pred_class_scores, (1, -1)).shape)\n",
    "print(pred_reg_scores.shape)\n",
    "# print(K.reshape(pred_reg_scores, (1, -1, 4)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions for RPN\n",
    "\n",
    "1. Classification Loss. (Binary Cross Entropy)\n",
    "2. Regression Loss. (Smooth L1 Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = K.get_value(K.reshape(pred_class_scores, (1, -1))[0])\n",
    "pred_box = K.get_value(K.reshape(pred_reg_scores, (1, -1, 4))[0])\n",
    "\n",
    "print(pred_class[:10])\n",
    "print(pred_box[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.38629436 3.29583687]\n",
      "[1.         3.38629436 6.29583687]\n",
      "[1 4 9]\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ####\n",
    "\n",
    "print(np.multiply([1,2,3], np.log([1, 2, 3])))\n",
    "print(np.add(np.multiply([1,2,3], np.log([1, 2, 3])), [1, 2, 3]))\n",
    "print(np.multiply([1, 2, 3], [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BINARY CROSS ENTROPY ###########\n",
    "\n",
    "def binary_crossentropy(y_pred, y_true):\n",
    "    n = y_true.shape[0]\n",
    "    x = np.multiply(y_true, np.log(y_pred))\n",
    "    xhat = np.multiply((1 - y_true), np.log(1 - y_pred))\n",
    "    return np.sum(x + xhat) * (-1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3862943611198906\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ###\n",
    "#### TESTING BINARY CROSSENTROPY ######\n",
    "\n",
    "pred = np.asarray([0.75, 0.25])\n",
    "true = np.asarray([0, 1])\n",
    "print(binary_crossentropy(y_pred = pred, y_true = true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## SMOOTH L1 LOSS ############\n",
    "\n",
    "def smooth_l1_loss(y_pred, y_true, delta = 1):\n",
    "    x = np.abs(y_pred - y_true)\n",
    "    return np.square(np.sum(x[x <= delta]))*0.5 + np.sum(delta * (x[x > delta] - 0.5 * delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07999999999999996\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ###\n",
    "#### TESTING SMOOTHL1 LOSS #####\n",
    "\n",
    "pred = np.asarray([[1, 2, 3]])\n",
    "true = np.asarray([[1.1, 2, 3.3]])\n",
    "\n",
    "print(smooth_l1_loss(pred, true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO\n",
    "\n",
    "1. Convert all NumPy vectors into Keras Tensors for Loss calculations.\n",
    "2. Define Data Generators.\n",
    "3. Start model training.\n",
    "4. Check the sampling done for loss calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras tensor\n",
      "(?, ?, ?, 3)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "Tensor(\"activation_80/Relu:0\", shape=(?, ?, ?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape = (None, None, 3))\n",
    "feature_map = nn_base(input, trainable = True)\n",
    "print(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reshape_3_1/Reshape:0\", shape=(?, ?, 1), dtype=float32) Tensor(\"reshape_4/Reshape:0\", shape=(?, ?, 4), dtype=float32) Tensor(\"activation_80/Relu:0\", shape=(?, ?, ?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_class_scores, pred_reg_scores, features = rpn(feature_map, k)\n",
    "print(pred_class_scores, pred_reg_scores, features)\n",
    "# rpn_output = rpn(feature_map, k)\n",
    "# print(rpn_output[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x000001AAB82467C8>\n"
     ]
    }
   ],
   "source": [
    "#### USING KERAS FUNCTIONAL API ####\n",
    "\n",
    "model_rpn = Model(input, [pred_class_scores, pred_reg_scores])\n",
    "# model_rpn = Model(input, rpn_output[:2])\n",
    "print(model_rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weights from C:\\Users\\Dyanesh\\Deep Learning\\keras_frcnn\\weights\\resnet50_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "### LOADING WEIGHTS FOR PRETRAINED RESNET ON IMAGENET DATASET ###\n",
    "\n",
    "weights_path = \"C:\\\\Users\\\\Dyanesh\\\\Deep Learning\\\\keras_frcnn\\\\weights\\\\resnet50_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "print(\"Getting weights from {}\".format(weights_path))\n",
    "model_rpn.load_weights(weights_path, by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 1e-5, clipnorm = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_loss_box_reg(y_true, y_pred):\n",
    "#     def smooth_l1_sample():\n",
    "    print(\"Regression Loss\")\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "#     return 0\n",
    "#     K\n",
    "    loss = K.abs(K.sum(y_true) - K.sum(y_pred))\n",
    "    return loss\n",
    "#     return K.placeholder(shape=(1,))\n",
    "#     return smooth_l1_sample\n",
    "\n",
    "HUBER_DELTA = 1\n",
    "def smoothL1(y_true, y_pred):\n",
    "   x   = K.abs(y_true - y_pred)\n",
    "   x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
    "   return  K.sum(x)\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def rpn_loss_cls(y_true, y_pred):\n",
    "#     def binary_crossentropy_sample(y_true, y_pred):\n",
    "    print(\"Classification Loss\")\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    loss = K.abs(K.sum(y_true) - K.sum(y_pred))\n",
    "    return loss\n",
    "#     return K.constant(1)\n",
    "#     return K.placeholder(shape=(1,))\n",
    "#     return binary_crossentropy_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 23:12:55.113102 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1204 23:12:55.137044 17700 deprecation.py:323] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls, rpn_loss_box_reg])\n",
    "model_rpn.compile(optimizer=optimizer, loss=[binary_crossentropy, smoothL1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Callbacks=keras.callbacks.ModelCheckpoint(\"./models/rpn/rpn.resnet.weights.{epoch:02d}-{loss:.2f}.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=4)\n",
    "callback=[Callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 3 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 5 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 5 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 5 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 5 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, None, None, 5 4719104     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, None, None, 9 4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, None, None, 3 18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, None, 1)      0           rpn_out_class[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, None, 4)      0           rpn_out_regress[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 13,331,373\n",
      "Trainable params: 13,300,781\n",
      "Non-trainable params: 30,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rpn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "\n",
    "### SAMPLE IMAGE ###\n",
    "\n",
    "data = {}\n",
    "data['img'] = img\n",
    "data['bboxs'] = bbox\n",
    "\n",
    "img_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(bboxs, anchor_scales, anchor_ratios, feature_map_size, subsampling_ratio):\n",
    "    \n",
    "    k = len(anchor_scales) * len(anchor_ratios)\n",
    "    anchors = np.zeros((k * feature_map_size * feature_map_size, 4))\n",
    "    \n",
    "    x = np.arange(subsampling_ratio/2, width, subsampling_ratio, dtype = np.int32)\n",
    "    \n",
    "    ### ANCHOR CENTRES ###\n",
    "    \n",
    "    anchor_centres = np.zeros((anchors.shape[0], 2))\n",
    "    anchor_centres[:, 0] = np.tile(np.repeat(x, k), feature_map_size) #XCOORDINATES\n",
    "    anchor_centres[:, 1] = np.repeat(x, k * feature_map_size) #YCOORDINATES\n",
    "    \n",
    "    ### ANCHOR BOX COORDINATES ###\n",
    "    \n",
    "    start_box_no = 0\n",
    "    for scale in anchor_scales:\n",
    "        for ratio in anchor_ratios:\n",
    "            w = subsampling_ratio * scale * np.sqrt(ratio)\n",
    "            h = subsampling_ratio * scale * (1/np.sqrt(ratio))\n",
    "\n",
    "            ### ANCHOR BOX COORDINATES WITH SCALEi, RATIOj###\n",
    "            anchor_coords = np.arange(start_box_no, anchor_centres.shape[0], step = k)\n",
    "\n",
    "            anchors[anchor_coords, 0] = anchor_centres[anchor_coords, 0] - w/2 # XMIN\n",
    "            anchors[anchor_coords, 2] = anchor_centres[anchor_coords, 0] + w/2 # YMIN\n",
    "            anchors[anchor_coords, 1] = anchor_centres[anchor_coords, 1] - h/2 # XMAX\n",
    "            anchors[anchor_coords, 3] = anchor_centres[anchor_coords, 1] + h/2 # YMAX\n",
    "\n",
    "            start_box_no += 1\n",
    "    \n",
    "    ### REMOVING OUT OF BOX ANCHORS ####\n",
    "    \n",
    "    filtered_anchors = anchors[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ]\n",
    "\n",
    "    ### CALCULATING IOUS ###\n",
    "    ious = np.zeros((bbox.shape[0], filtered_anchors.shape[0]), dtype = np.float64)\n",
    "\n",
    "    for i,a in enumerate(bbox):\n",
    "        for j,b in enumerate(filtered_anchors):\n",
    "            ious[i,j] = IoU(a, b)\n",
    "\n",
    "    ## BEST ANCHOR FOR EACH GROUND TRUTH ##\n",
    "    gt_best_arg_anchors = ious.argmax(axis = 1)\n",
    "\n",
    "    ## BEST ANCHOR IOUS ##\n",
    "    gt_best_anchors_ious = ious.max(axis = 1)\n",
    "\n",
    "    ## ANCHORS THAT HAVE IOU EQUAL TO BEST ANCHOR IOU ##\n",
    "    gt_best_anchors = np.where(np.isin(ious, gt_best_anchors_ious))[1]\n",
    "    \n",
    "    anchor_best_arg_gt = ious.argmax(axis = 0)\n",
    "    anchor_best_gt_ious = ious.max(axis = 0)\n",
    "    \n",
    "    ### LABELS ###\n",
    "    \n",
    "    labels = np.full((filtered_anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "    positive_threshold = 0.7\n",
    "    negative_threshold = 0.3\n",
    "\n",
    "    ### POSITIVE LABELS ###\n",
    "    ## CONDITION 1\n",
    "\n",
    "    labels[gt_best_anchors] = 1\n",
    "\n",
    "    ## CONDITION 2\n",
    "\n",
    "    labels[anchor_best_gt_ious >= positive_threshold] = 1\n",
    "    ### NGEATIVE LABELS ###\n",
    "\n",
    "    labels[anchor_best_gt_ious < negative_threshold] = 0    \n",
    "    \n",
    "    ### SAMPLING ###\n",
    "    \n",
    "    sample_size = 256\n",
    "    pos_ratio = 0.5\n",
    "\n",
    "    pos_size = sample_size * pos_ratio\n",
    "    neg_size = sample_size - pos_size\n",
    "    \n",
    "    pos_labels = labels[labels == 1]\n",
    "    neg_labels = labels[labels == 0]\n",
    "    disabled_labels = labels[labels == -1]\n",
    "    \n",
    "    ### DISABLING ANCHORS ###\n",
    "\n",
    "    if len(pos_labels) > pos_size:\n",
    "        pos_indices = np.where(labels == 1)[0]\n",
    "        disabled_indices = np.random.choice(pos_indices, len(pos_labels) - pos_size, replace = False)\n",
    "        labels[disabled_indices] = -1\n",
    "\n",
    "    ## UPDATE NO. OF POSITIVE LABELS ##\n",
    "    pos_size = len(pos_labels)\n",
    "\n",
    "    if len(neg_labels) > sample_size - pos_size:\n",
    "        neg_indices = np.where(labels == 0)[0]\n",
    "        disabled_indices = np.random.choice(neg_indices, len(neg_indices) - pos_size, replace = False)\n",
    "        labels[disabled_indices] = -1\n",
    "\n",
    "    ## UPDATE NO. OF NEGATIVE LABELS ##\n",
    "    neg_size = pos_size\n",
    "    \n",
    "    anchor_best_gt_boxes_coords = bbox[anchor_best_arg_gt]\n",
    "\n",
    "    ## CALCULATING ANCHOR BOX XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "    anchor_w = filtered_anchors[:,2] - filtered_anchors[:,0]\n",
    "    anchor_h = filtered_anchors[:,3] - filtered_anchors[:,1]\n",
    "\n",
    "    anchor_x_c = filtered_anchors[:,0] + 0.5 * anchor_w\n",
    "    anchor_y_c = filtered_anchors[:,1] + 0.5 * anchor_h\n",
    "    \n",
    "    ## CALCULATING GROUND TRUTH XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "    gt_w = anchor_best_gt_boxes_coords[:,2] - anchor_best_gt_boxes_coords[:,0]\n",
    "    gt_h = anchor_best_gt_boxes_coords[:,3] - anchor_best_gt_boxes_coords[:,1]\n",
    "\n",
    "    gt_x_c = anchor_best_gt_boxes_coords[:,0] + 0.5 * gt_w\n",
    "    gt_y_c = anchor_best_gt_boxes_coords[:,1] + 0.5 * gt_h\n",
    "    \n",
    "    ## PARAMETERISING ##\n",
    "\n",
    "    t_x = (gt_x_c - anchor_x_c)/anchor_w\n",
    "    t_y = (gt_y_c - anchor_y_c)/anchor_h\n",
    "    t_w = np.log(gt_w/anchor_w)\n",
    "    t_h = np.log(gt_h/anchor_h)\n",
    "\n",
    "    t_anchors = np.zeros((filtered_anchors.shape[0], 4))\n",
    "    t_anchors[:,0] = t_x\n",
    "    t_anchors[:,1] = t_y\n",
    "    t_anchors[:,2] = t_w\n",
    "    t_anchors[:,3] = t_h\n",
    "    \n",
    "    anchor_targets = np.zeros((anchors.shape[0], 4))\n",
    "\n",
    "    anchor_targets[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ] = t_anchors\n",
    "\n",
    "    anchor_labels = np.full((anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "    anchor_labels[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ] = labels\n",
    "\n",
    "    return anchor_labels, anchor_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(img_data, anchor_scales, anchor_ratios, feature_map_size, subsampling_ratio):\n",
    "    while True:\n",
    "        for data in img_data:\n",
    "            img = np.expand_dims(data['img'], axis = 0)\n",
    "            bboxs= data['bboxs']\n",
    "            anchor_cls_targets, anchor_reg_targets = get_targets(bboxs, anchor_scales, anchor_ratios, feature_map_size=feature_map_size, subsampling_ratio=subsampling_ratio)\n",
    "            print(anchor_cls_targets.shape, anchor_reg_targets.shape, img.shape)\n",
    "            anchor_cls_targets = np.expand_dims(anchor_cls_targets, axis = 0).reshape((1, -1, 1))\n",
    "            anchor_reg_targets = np.expand_dims(anchor_reg_targets, axis = 0).reshape((1, -1, 4))\n",
    "            yield np.copy(img), [np.copy(anchor_cls_targets), np.copy(anchor_reg_targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/reshape_6_loss/Mean_2/_3999]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ca431221affe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_rpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_map_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/reshape_6_loss/Mean_2/_3999]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "history = model_rpn.fit_generator(train_generator(img_data, scales, ratios, feature_map_size, subsampling_ratio), epochs=1, steps_per_epoch = 1, callbacks=callback)\n",
    "loss_history = history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "> There seems to be an issue in the loss function. This is because the tensors used belong to the Tensorflow Framework. \\\n",
    "To mitigate this, I need to learn how to use those tensors. That's what this section will be about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(12,), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(1, 3, 4), dtype=float32)\n",
      "Tensor(\"Reshape_6:0\", shape=(1, 36864, 4), dtype=float32)\n",
      "Predicted Shape = (1, 64, 64, 36)\n",
      "Targets Shape = (1, 36864, 4)\n",
      "Tensor(\"Abs:0\", shape=(1, 36864, 4), dtype=float32)\n",
      "Tensor(\"Square:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"LessEqual:0\", shape=(1, 36864, 4), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "a = K.constant([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "print(a)\n",
    "\n",
    "b = K.reshape(a, (1,-1, 4))\n",
    "print(b)\n",
    "\n",
    "### Predicted.\n",
    "c = K.ones((1, 64, 64, 36))\n",
    "print(K.reshape(c, (1, -1, 4)))\n",
    "\n",
    "\n",
    "### Targets.\n",
    "\n",
    "d = K.ones((1, 36864, 4))\n",
    "\n",
    "\n",
    "print(\"Predicted Shape = {}\".format(c.shape))\n",
    "print(\"Targets Shape = {}\".format(d.shape))\n",
    "\n",
    "\n",
    "###  NOW WE HAVE TO CALCULATE HUBER'S LOSS ###\n",
    "c = K.reshape(c, (1, -1, 4))\n",
    "\n",
    "x = K.abs(c - d)\n",
    "print(x)\n",
    "\n",
    "less_than_delta = K.less_equal(x, 1)\n",
    "print(K.square(x[less_than_delta] * 0.5))\n",
    "\n",
    "print(less_than_delta)\n",
    "\n",
    "# print(c[c < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUBER_DELTA = 1\n",
    "def smoothL1(y_true, y_pred):\n",
    "   x   = K.abs(y_true - y_pred)\n",
    "   x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
    "   return  K.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04999999999999996"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.asarray([1, 2, 3])\n",
    "d = np.asarray([1.1, 2, 3.3])\n",
    "K.eval(smoothL1(c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = K.constant([1, 1, 1e-5, 1, 0, 1, 0, 1], dtype = 'float32')\n",
    "b = K.constant([0.5, 1, 1e-7, 0, 1, 1, 1, 0], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.101784\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(K.mean(K.binary_crossentropy(a,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.6931472,   0.       , -16.118095 ,        -inf,   0.       ,\n",
       "         0.       ,   0.       ,        -inf], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(K.log(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    y_true = K.switch(y_true <= 0, 1e-15, y_true)\n",
    "    y_pred = K.switch(y_pred <= 0, 1e-15, y_pred)\n",
    "#     y_true = K.cast(y_true, 'float32') + 1e-7\n",
    "#     y_pred = K.cast(y_pred, 'float32') + 1e-7\n",
    "    a = y_true * K.log(y_pred)\n",
    "    print(K.eval(a))\n",
    "    b = (1 - y_true) * K.log(1 - y_pred) \n",
    "    print(K.eval(b))\n",
    "#     sum = K.sum(a + b)\n",
    "\n",
    "#     n = K.mean()\n",
    "#     return sum\n",
    "    return -1*K.mean(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-e7a79ff99ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-b20ed44d5e20>\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     y_true = K.cast(y_true, 'float32') + 1e-7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     y_pred = K.cast(y_pred, 'float32') + 1e-7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mswitch\u001b[1;34m(condition, then_expression, else_expression)\u001b[0m\n\u001b[0;32m   3065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melse_expression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3066\u001b[0m             \u001b[0melse_expression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melse_expression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3067\u001b[1;33m         \u001b[0mexpr_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthen_expression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcond_ndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mexpr_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m             raise ValueError('Rank of `condition` should be less than or'\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mndim\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m     \"\"\"\n\u001b[1;32m--> 619\u001b[1;33m     \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "print(K.eval(binary_crossentropy(a, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Proposals for Faster RCNN\n",
    "> If we have successfully trained the network, we would have the following -\n",
    "    > -  Objectness Scores or Classification Scores.\n",
    "    > -  Predicted Boxes Coordinates.\n",
    "\n",
    "> To reduce the no. of proposals generated, we are applying Non-Maximum Suppression (NMS).\n",
    "> After applying NMS, we will be taking only a number of top proposals sorted according to their classification scores.\n",
    "\n",
    "- Researchers say that the reduction in the number of proposals doesnot affect the results. For the moment, let's keep that belief and work on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SINCE WE ARE LACKING THE RESOURCES TO RUN THE RPN, WE WILL BE GENERATING RANDOM SCORES AND LOCATIONS TO CONTINUE OUR WORK. ITS REALLY SAD AND DEPRESSING.STOP COMPLAINING AND START WORKING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Classification Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 36864, 1)\n"
     ]
    }
   ],
   "source": [
    "pred_cls_scores = np.random.normal(size=(1, 36864, 1))\n",
    "\n",
    "## PROBABILITY CANT BE NEGATIVE ##\n",
    "\n",
    "pred_cls_scores[(pred_cls_scores < 0) | (pred_cls_scores > 1)] = 0\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Regression Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 36864, 4)\n"
     ]
    }
   ],
   "source": [
    "pred_reg_scores = np.random.normal(size=(1, 36864, 4))\n",
    "print(pred_reg_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholds for Non-Maximum Supression\n",
    "\n",
    "- Whether we are training or testing.\n",
    "- Minimum IOU threshold for combining proposals. Redundancy is reduced majorly here.\n",
    "- No. of proposals before NMS in testing/training.\n",
    "- No. of proposals after NMS in testing/training.\n",
    "- Minimum height/width of proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_thresh = 0.7\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Location Predictions from RPN to Bounding Boxes\n",
    "\n",
    "- Unparameterize the Predictions.\n",
    "- Convert dxc, dxy, dh, dw into xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "(36864,)\n",
      "[[ -99.520775    38.29225     25.52587    154.25854  ]\n",
      " [   2.3767023   42.496452    92.419754   236.17397  ]\n",
      " [ -66.855316  -365.69348     -9.587412   391.69382  ]]\n"
     ]
    }
   ],
   "source": [
    "### formula ###\n",
    "\n",
    "'''\n",
    "x = w(anchor) * dxc(p) + xc(anchor)\n",
    "y = h(anchor) * dxc(p) + yc(anchor)\n",
    "h = exp(dh(p)) * h(anchor)\n",
    "w = exp(dw(p)) * w(anchor)\n",
    "\n",
    "'''\n",
    "\n",
    "##  CALCULATING ANCHOR PARAMETERS\n",
    "\n",
    "anchors_height = anchors[:, 3] - anchors[:, 1]\n",
    "anchors_width = anchors[:, 2] - anchors[:, 0]\n",
    "anchors_xc = anchors[:, 0] + 0.5 * anchors_width\n",
    "anchors_yc = anchors[:, 1] + 0.5 * anchors_height\n",
    "\n",
    "\n",
    "print(anchors_height.shape)\n",
    "print(anchors_yc.shape)\n",
    "\n",
    "\n",
    "\n",
    "## EXTRACTING PREDICTIONS FROM REGRESSION OUTPUT ##\n",
    "\n",
    "pred_dxc = pred_reg_scores[0,:,0]\n",
    "pred_dyc = pred_reg_scores[0,:,1]\n",
    "pred_dh = pred_reg_scores[0,:,2]\n",
    "pred_dw = pred_reg_scores[0,:,3]\n",
    "\n",
    "print(pred_dxc.shape)\n",
    "print(pred_dw.shape)\n",
    "\n",
    "\n",
    "## EXTRACTING OBJECTNESS SCORES FROM CLASSIFICATION OUTPUT ## \n",
    "\n",
    "objectness_scores = pred_cls_scores[0, :, 0]\n",
    "\n",
    "\n",
    "## APPLYING FORMULA FOR UNPARAMETERISATION ##\n",
    "\n",
    "\n",
    "pred_xc = pred_dxc * anchors_width + anchors_xc\n",
    "pred_yc = pred_dyc * anchors_height + anchors_yc\n",
    "pred_h = np.exp(pred_dh) * anchors_height\n",
    "pred_w = np.exp(pred_dw) * anchors_width\n",
    "\n",
    "print(pred_xc.shape)\n",
    "print(pred_w.shape)\n",
    "\n",
    "\n",
    "## CONVERTING TO BOUDNING BOX COORDINATES ##\n",
    "\n",
    "\n",
    "pred_xmin = pred_xc - 0.5 * pred_w\n",
    "pred_xmax = pred_xc + 0.5 * pred_w\n",
    "pred_ymin = pred_yc - 0.5 * pred_h\n",
    "pred_ymax = pred_yc + 0.5 * pred_h\n",
    "\n",
    "\n",
    "print(pred_ymax.shape)\n",
    "print(pred_xmin.shape)\n",
    "\n",
    "rois = np.zeros((anchors.shape[0], 4), dtype = np.float32)\n",
    "rois[:, 0] = pred_xmin\n",
    "rois[:, 1] = pred_ymin\n",
    "rois[:, 2] = pred_xmax\n",
    "rois[:, 3] = pred_ymax\n",
    "\n",
    "print(rois[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  38.29225 ,  154.25854 ],\n",
       "       [  42.496452,  236.17397 ],\n",
       "       [-365.69348 ,  391.69382 ],\n",
       "       ...,\n",
       "       [1726.7717  , 2144.5     ],\n",
       "       [1011.49396 , 1472.5171  ],\n",
       "       [ 341.45135 , 1796.6119  ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois[:,[1, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, they are out of image proposals generated. We need to keep them inside by clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.          38.29225     25.52587    154.25854  ]\n",
      " [   2.3767023   42.496452    92.419754   236.17397  ]\n",
      " [   0.           0.           0.         391.69382  ]\n",
      " [   0.           0.         369.47177     26.06432  ]\n",
      " [  71.26292      6.3297963  256.02853     81.87051  ]\n",
      " [   0.          39.532433   157.40517    224.73961  ]\n",
      " [   0.           0.        1024.         893.2947   ]\n",
      " [   0.           0.         870.039     1024.       ]\n",
      " [ 441.94522      0.        1024.         162.75804  ]\n",
      " [  38.84046      0.         110.970535   195.47208  ]]\n"
     ]
    }
   ],
   "source": [
    "## CLIPPING X-COORDINATES ##\n",
    "\n",
    "rois[:, (0, 2)] = np.clip(rois[:, (0, 2)], 0, width)\n",
    "\n",
    "## CLIPPING Y-COORDINATES ##\n",
    "\n",
    "rois[:, (1, 3)] = np.clip(rois[:, (1, 3)], 0, height)\n",
    "\n",
    "print(rois[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Regions whose height or width is lesser than the Threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28085, 4)\n",
      "(28085,)\n"
     ]
    }
   ],
   "source": [
    "rois_h = rois[:, 3] - rois[:, 1]\n",
    "rois_w = rois[:, 2] - rois[:, 0]\n",
    "\n",
    "rois = rois[(rois_h >= min_size) & (rois_w >= min_size)]\n",
    "objectness_scores = objectness_scores[(rois_h >= min_size) & (rois_w >= min_size)]\n",
    "\n",
    "\n",
    "print(rois.shape)\n",
    "print(objectness_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting and Choosing the top N Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28085,)\n",
      "(12000,)\n",
      "(12000,)\n",
      "(12000,)\n",
      "[[ 953.44745    318.6558    1024.         430.48746  ]\n",
      " [ 369.32147      2.3751333  584.84283    131.1767   ]\n",
      " [ 347.8285     220.29532    599.2389     394.81778  ]\n",
      " [ 562.86804     46.53373    599.707      382.1605   ]\n",
      " [ 157.35573     63.79439    247.46269    255.02077  ]]\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(objectness_scores)[::-1][:n_train_pre_nms]\n",
    "\n",
    "print(objectness_scores.shape)\n",
    "print(sorted_indices.shape)\n",
    "\n",
    "\n",
    "rois = rois[sorted_indices]\n",
    "objectness_scores = objectness_scores[sorted_indices]\n",
    "\n",
    "print(objectness_scores.shape)\n",
    "print(sorted_indices.shape)\n",
    "print(rois[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression\n",
    "\n",
    "> This is where regions with high overlaps are merged. This reduces the overall number of regions proposed by RPN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(12000,)\n",
      "5806\n",
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "final_rois = []\n",
    "\n",
    "ordered_indices = np.argsort(objectness_scores)[::-1].astype(np.int32)\n",
    "\n",
    "print(ordered_indices[:10])\n",
    "print(objectness_scores.shape)\n",
    "\n",
    "roi_x1, roi_x2, roi_y1, roi_y2 = rois[:,0], rois[:, 1], rois[:, 2], rois[:, 3]\n",
    "areas = (roi_x2 - roi_x1 + 1) * (roi_y2 - roi_y1 + 1)\n",
    "\n",
    "while ordered_indices.size > 0:\n",
    "    \n",
    "    top = ordered_indices[0]\n",
    "    \n",
    "    final_rois.append(rois[top])\n",
    "\n",
    "    ## CALCULATE IOUS WITH OTHER REGIONS ##\n",
    "\n",
    "    x1 = np.maximum(roi_x1[top], roi_x1[ordered_indices[1:]])\n",
    "    x2 = np.maximum(roi_x2[top], roi_x2[ordered_indices[1:]])\n",
    "    y1 = np.minimum(roi_y1[top], roi_y1[ordered_indices[1:]])\n",
    "    y2 = np.minimum(roi_y2[top], roi_y2[ordered_indices[1:]])\n",
    "    \n",
    "    w = np.maximum(0.0, x2 - x1 + 1)\n",
    "    h = np.maximum(0.0, y2 - y1 + 1)\n",
    "    \n",
    "    intersection = h * w\n",
    "    union = areas[top] + areas[ordered_indices[1:]] - intersection\n",
    "    \n",
    "    ious = intersection / union\n",
    "    \n",
    "    ## REMOVE OVERLAPPING REGIONS\n",
    "    \n",
    "    valid_indicdes = np.where(ious <= nms_thresh)[0]\n",
    "    \n",
    "    ordered_indices = ordered_indices[valid_indicdes + 1]\n",
    "    \n",
    "    \n",
    "print(len(final_rois))\n",
    "\n",
    "final_rois = np.asarray(final_rois[:n_train_post_nms], dtype = np.float32)\n",
    "\n",
    "print(final_rois.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Targets for R-CNN Network.\n",
    "\n",
    "> It is from this output that we have to take 128 samples. My earlier confusion should get cleared up here. Let's see. Okay, now, let's see what we are supposed to do here - \n",
    "> - No. of Regions to sample - 128\n",
    "> - Positive Ratio - 0.5\n",
    "> - Minimum IOU Threshold for Positive Sample - 0.5\n",
    "> - IOU < 0.5 => Negative Sample or Background Sample.\n",
    "\n",
    "> Algorithm - \n",
    "> - For each possible combination of Region and Ground-truth, find IOU.\n",
    "> > - For each Region, find which Ground-truth has max IOU. If its greater than threshold, assign the class label.\n",
    "> > - Then, we randomly sample samples * ratio and consider them as positive labels. If the IOU is lesser than threshold, we assign negative label.\n",
    "> > - We sample randomly again, the remaining for the 128 - pos regions and assign negative labels.\n",
    "\n",
    "That's it. We are officialy done with sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THRESHOLDS ##\n",
    "\n",
    "n_sample = 128\n",
    "pos_ratio = 0.25\n",
    "pos_iou_threshold = 0.5\n",
    "neg_iou_threshold_low, neg_iou_threshold_high = 0.0, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2000)\n"
     ]
    }
   ],
   "source": [
    "## CALCULATING IOUs ##\n",
    "\n",
    "\n",
    "gt_region_ious = np.empty((bbox.shape[0], final_rois.shape[0]), dtype = np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for i, gtbox in enumerate(bbox):\n",
    "    for j, region in enumerate(final_rois):\n",
    "        gt_region_ious[i, j] = IoU(a = gtbox, b = region)\n",
    "        \n",
    "        \n",
    "print(gt_region_ious.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "## FINDING GROUNDTRUTH FOR WHICH REGION HAS MAX IOU ##\n",
    "\n",
    "gt_region_max_ious = np.max(gt_region_ious, axis = 0)\n",
    "gt_region_argmax_ious = np.argmax(gt_region_ious, axis = 0)\n",
    "\n",
    "print(gt_region_max_ious.shape)\n",
    "\n",
    "\n",
    "## GREATER THAN THRESHOLD ##\n",
    "print(gt_region_max_ious[gt_region_max_ious < pos_iou_threshold].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASS LABELS FOR GROUND TRUTHS ##\n",
    "\n",
    "labels = np.asarray([6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "## INCASE U FORGET THE POWER OF BROADCASTING ## LOOK HERE\n",
    "\n",
    "print(labels[[0,0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "## ASSIGNING LABELS TO MAX GROUNDTRUTH PROPOSALS ##\n",
    "\n",
    "print(labels[gt_region_argmax_ious].shape)\n",
    "\n",
    "gt_region_labels = labels[gt_region_argmax_ious]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## ASSIGNING POSITIVE LABELS ##\n",
    "\n",
    "positive_samples = np.where(gt_region_max_ious > pos_iou_threshold)[0]\n",
    "print(positive_samples)\n",
    "\n",
    "positive_samples_size = min(positive_samples.size, n_sample * pos_ratio)\n",
    "\n",
    "if positive_samples.size > 0:\n",
    "    positive_samples = np.random.choice(positive_samples, size = positive_samples_size, replace = False)\n",
    "\n",
    "print(positive_samples_size)\n",
    "print(positive_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  45  191 1127 1627 1410 1394 1346 1191 1231   73  727 1498  107  495\n",
      "  792 1967  789 1480 1787  298  846  892 1766 1747 1953  895  591 1465\n",
      " 1580  934 1433  857 1366  578  865  595  920 1815  289 1610  589  995\n",
      " 1179 1422  471  390  694  948 1969  521  467  373  695 1417  478  167\n",
      " 1656  126 1819  563 1604  401 1200  491 1187  742 1710  224  959  312\n",
      " 1279 1328 1599 1440  828  566 1858  514  898   44 1917 1565  853 1163\n",
      "  165 1099 1082 1752 1857  481  308 1212  371 1934   88 1980 1224 1458\n",
      " 1682  177 1421  184  523 1240  212   55  663 1025 1205 1484  185  112\n",
      "  891 1020  347 1667 1706 1223 1412  425  132  749 1232 1722 1132  771\n",
      " 1355  950]\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "## ASSIGNING NEGATIVE LABELS ##\n",
    "\n",
    "negative_samples = np.where((gt_region_max_ious >= neg_iou_threshold_low) & (gt_region_max_ious < neg_iou_threshold_high))[0]\n",
    "negative_samples_size = min(negative_samples.size, n_sample - positive_samples_size)\n",
    "\n",
    "\n",
    "if negative_samples.size > 0:\n",
    "    negative_samples = np.random.choice(negative_samples, size = negative_samples_size, replace = False)\n",
    "    \n",
    "\n",
    "print(negative_samples)\n",
    "print(negative_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(128,)\n",
      "(128, 4)\n"
     ]
    }
   ],
   "source": [
    "## COMBINING NEGATIVE AND POSITIVE SAMPLES ##\n",
    "\n",
    "samples_indices = np.append(positive_samples, negative_samples)\n",
    "print(samples_indices.shape)\n",
    "\n",
    "\n",
    "## SAMPLES LABELS ##\n",
    "samples_labels = np.append(gt_region_labels[positive_samples], np.zeros(negative_samples_size))\n",
    "print(samples_labels.shape)\n",
    "\n",
    "\n",
    "## SAMPLE BBOXS ##\n",
    "samples_rois = final_rois[samples_indices]\n",
    "print(samples_rois.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "[[  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [ 400  800  800 1000]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]]\n"
     ]
    }
   ],
   "source": [
    "## GROUNDTRUTH BOXES FOR SAMPLES ROIS ##\n",
    "\n",
    "gt_samples_rois = bbox[gt_region_argmax_ious[samples_indices]]\n",
    "print(gt_samples_rois.shape)\n",
    "\n",
    "print(gt_samples_rois[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, we have the sample regions, their labels. Before we feed them into the ROI netowrk, we need to parameterize them, like we did before for RPN. I mean, the same formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERISING ##\n",
    "\n",
    "## XC,YX,H,W Format ##\n",
    "\n",
    "\n",
    "## SAMPLES ##\n",
    "samples_rois_h = samples_rois[:, 3] - samples_rois[:, 1]\n",
    "samples_rois_w = samples_rois[:, 2] - samples_rois[:, 0]\n",
    "\n",
    "samples_rois_xc = samples_rois[:, 0] + 0.5 * samples_rois_w\n",
    "samples_rois_yc = samples_rois[:, 1] + 0.5 * samples_rois_h\n",
    "\n",
    "\n",
    "## GTBBOXS ##\n",
    "gt_samples_rois_h = gt_samples_rois[:, 3] - gt_samples_rois[:, 1]\n",
    "gt_samples_rois_w = gt_samples_rois[:, 2] - gt_samples_rois[:, 0]\n",
    "\n",
    "gt_samples_rois_xc = gt_samples_rois[:, 0] + 0.5 * gt_samples_rois_w\n",
    "gt_samples_rois_yc = gt_samples_rois[:, 1] + 0.5 * gt_samples_rois_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "[[ -3.58641375  -1.09752929  -1.31051314   0.91668593]\n",
      " [ -1.69518557  -0.76091868  -2.02585788   1.55021638]\n",
      " [ -0.56782545  -0.29478242  -1.73783517   0.22439626]\n",
      " [ -0.60517788   0.37890625  -1.63315444   0.04173746]\n",
      " [-12.62924466  -0.14045737  -0.82726739   1.82672821]\n",
      " [ -0.28279866  -2.89182425  -0.38426139  -0.93386678]\n",
      " [ -1.01505184  -0.25612565  -1.56525281   1.49135153]\n",
      " [ -1.37374779  -0.12998739  -1.14836886  -0.13384852]\n",
      " [ -7.27569092  -1.28879363  -1.44851384   1.46662023]\n",
      " [ -0.78387659  -7.32905482  -0.15694393  -0.36477341]]\n"
     ]
    }
   ],
   "source": [
    "## APPLYING FORMULAS ##\n",
    "\n",
    "samples_rois_h = np.maximum(samples_rois_h, np.finfo(samples_rois_h.dtype).eps)\n",
    "samples_rois_w = np.maximum(samples_rois_w, np.finfo(samples_rois_w.dtype).eps)\n",
    "\n",
    "dx = (gt_samples_rois_xc - samples_rois_xc) / samples_rois_w\n",
    "dy = (gt_samples_rois_yc - samples_rois_yc) / samples_rois_h\n",
    "dh = np.log(gt_samples_rois_h / samples_rois_h)\n",
    "dw = np.log(gt_samples_rois_w / samples_rois_w)\n",
    "\n",
    "\n",
    "samples_locations = np.empty((dx.shape[0], 4), dtype = dx.dtype)\n",
    "\n",
    "samples_locations[:, 0] = dx\n",
    "samples_locations[:, 1] = dy\n",
    "samples_locations[:, 2] = dh\n",
    "samples_locations[:, 3] = dw\n",
    "\n",
    "print(samples_locations.shape)\n",
    "print(samples_locations[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(128, 4)\n"
     ]
    }
   ],
   "source": [
    "print(samples_labels.shape)\n",
    "print(samples_locations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Pooling\n",
    "\n",
    "> We have to extract fix-sized feature maps from the feature maps. This is what that will be fed to the feed-forward network.\n",
    "> To do this, take a proposal and using the coordinates, crop the corresponding feature map and for the moment, resize it to the desired size.\n",
    "> In our case, the size is (7,7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 678.9495    202.94104   830.88947   425.4256  ]\n",
      " [ 306.37592   188.70674   387.0127    643.6635  ]\n",
      " [ 230.59311     0.        534.2125    341.10138 ]\n",
      " [ 640.3514      0.       1024.       1024.      ]\n",
      " [ 951.78723    20.662256 1012.94415   157.8859  ]\n",
      " [   0.        280.74783   966.84485   368.8596  ]\n",
      " [ 254.0503      0.        339.57623   287.03305 ]\n",
      " [ 589.57654     0.       1024.        189.18274 ]\n",
      " [ 804.00775   271.4634    891.67523   526.8704  ]\n",
      " [ 365.35754   549.371     912.62885   619.5668  ]]\n",
      "[[42.434345 12.683815 51.93059  26.5891  ]\n",
      " [19.148495 11.794171 24.188293 40.22897 ]\n",
      " [14.412069  0.       33.388283 21.318836]\n",
      " [40.02196   0.       64.       64.      ]\n",
      " [59.486702  1.291391 63.30901   9.867868]\n",
      " [ 0.       17.54674  60.427803 23.053724]\n",
      " [15.878143  0.       21.223515 17.939566]\n",
      " [36.848534  0.       64.       11.823921]\n",
      " [50.250484 16.966463 55.729702 32.9294  ]\n",
      " [22.834846 34.335686 57.039303 38.722923]]\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "## These are the region proposals in the x1, y1, x2, y2\n",
    "\n",
    "samples_rois\n",
    "\n",
    "\n",
    "## We need to resize them to the desired size.\n",
    "#\n",
    "#\n",
    "#\n",
    "##\n",
    "# Wait, how do we do that? Okay we have the region proposals. Which is in coordinate system of the entire image.\n",
    "# So, we need to subsample it to the feauture map size. Now, it will be in terms of feature map extracted from the backbone.\n",
    "# From this, we need to extract the proposal feature map. \n",
    "## This proposal feature map should be resized to the desired pool size.\n",
    "# Sounds easy... Let's try.\n",
    "#\n",
    "#\n",
    "##\n",
    "\n",
    "print((samples_rois)[:10])\n",
    "print((samples_rois/subsampling_ratio)[:10])\n",
    "\n",
    "\n",
    "\n",
    "downsampled_samples_rois = samples_rois/subsampling_ratio\n",
    "print(downsampled_samples_rois[downsampled_samples_rois > 64].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_feature_map_size = (14,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "Original Proposal Feauture Map size: (?, ?, ?, 1024).\n",
      "Fixed Shape Feature Map Size: (?, 14, 14, 1024).\n",
      "(1, 128, 14, 14, 1024)\n"
     ]
    }
   ],
   "source": [
    "final_feature_maps = []\n",
    "\n",
    "for roi in downsampled_samples_rois:\n",
    "    x1,y1,x2,y2 = roi.astype(np.int32)\n",
    "    h,w = y2-y1, x2-x1\n",
    "    \n",
    "    ## Extracting feature map for each proposal.\n",
    "    \n",
    "    proposal_feature_map = feature_map[:,y1:y2,x1:x2,:]\n",
    "    print(\"Original Proposal Feauture Map size: {}.\".format(proposal_feature_map.shape))\n",
    "    \n",
    "    ## Reisze each map to the pool size.\n",
    "    \n",
    "    fixed_roi_feature_map = tf.image.resize_images(proposal_feature_map, (fixed_feature_map_size[0], fixed_feature_map_size[1]))\n",
    "\n",
    "    print(\"Fixed Shape Feature Map Size: {}.\".format(fixed_roi_feature_map.shape))\n",
    "    \n",
    "    final_feature_maps.append(fixed_roi_feature_map)\n",
    "    \n",
    "    \n",
    "final_feature_maps = K.reshape(final_feature_maps, (1, downsampled_samples_rois.shape[0], fixed_feature_map_size[0], fixed_feature_map_size[1], 1024))\n",
    "print(final_feature_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block_td(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    # identity block time distributed\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), trainable=trainable, kernel_initializer='normal',padding='same'), name=conv_name_base + '2b')(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2c')(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def conv_block_td(input_tensor, kernel_size, filters, stage, block, input_shape, strides=(2, 2), trainable=True):\n",
    "    # conv block time distributed\n",
    "    \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), input_shape=input_shape, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2b')(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), kernel_initializer='normal'), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
    "    \n",
    "    shortcut = TimeDistributed(Convolution2D(nb_filter3, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = TimeDistributed(BatchNormalization(axis=bn_axis), name=bn_name_base + '1')(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def classifier_layers(x, input_shape, trainable=False):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a', input_shape=input_shape, strides=(2, 2), trainable=trainable)\n",
    "    elif K.backend() == 'theano':\n",
    "        x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a', input_shape=input_shape, strides=(1, 1), trainable=trainable)\n",
    "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='b', trainable=trainable)\n",
    "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='c', trainable=trainable)\n",
    "    x = TimeDistributed(AveragePooling2D((7, 7)), name='avg_pool')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 23:38:17.959216 17700 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (n_sample,14,14,1024)\n",
    "out = classifier_layers(final_feature_maps, input_shape=input_shape, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"avg_pool/transpose_1:0\", shape=(1, ?, 1, 1, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = TimeDistributed(Flatten())(out)\n",
    "\n",
    "nb_classes = len(labels) + 1\n",
    "out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
    "out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_1/transpose_1:0\", shape=(1, ?, 2048), dtype=float32)\n",
      "Tensor(\"dense_class_3/transpose_1:0\", shape=(1, ?, 3), dtype=float32)\n",
      "Tensor(\"dense_regress_3/transpose_1:0\", shape=(1, ?, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(out_class)\n",
    "print(out_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining ROI Pooling as a Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "### DEFINING A KERASS LAYER ###\n",
    "\n",
    "'''\n",
    "Define the follwoing functions and wrap it in a class.\n",
    "1. Call()\n",
    "2. Build()\n",
    "3. ComputeShape()\n",
    "'''\n",
    "###############################\n",
    "\n",
    "class RoiPoolingConv(Layer):\n",
    "\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "        self.pool_size = pool_size\n",
    "        self.num_rois = num_rois\n",
    "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.nb_channels = input_shape[0][3]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        assert(len(x) == 2)\n",
    "        img = x[0]\n",
    "        rois = x[1]\n",
    "        input_shape = K.shape(img)\n",
    "        outputs = []\n",
    "\n",
    "        for roi_idx in range(self.num_rois):\n",
    "            x = rois[0, roi_idx, 0]\n",
    "            y = rois[0, roi_idx, 1]\n",
    "            w = rois[0, roi_idx, 2]\n",
    "            h = rois[0, roi_idx, 3]\n",
    "            \n",
    "            row_length = w / float(self.pool_size)\n",
    "            col_length = h / float(self.pool_size)\n",
    "\n",
    "            num_pool_regions = self.pool_size\n",
    "\n",
    "            x = K.cast(x, 'int32')\n",
    "            y = K.cast(y, 'int32')\n",
    "            w = K.cast(w, 'int32')\n",
    "            h = K.cast(h, 'int32')\n",
    "\n",
    "            rs = tf.image.resize_images(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "            outputs.append(rs)\n",
    "\n",
    "        final_output = K.concatenate(outputs, axis=0)\n",
    "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
    "\n",
    "        # final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
    "        return final_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        pooling_regions = 14\n",
    "        input_shape = (num_rois,14,14,1024)\n",
    "\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
    "    out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)\n",
    "    out = TimeDistributed(Flatten())(out)\n",
    "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
    "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
    "    return [out_class, out_regr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_input = Input(shape=(None, None, 1024))\n",
    "roi_input = Input(shape=(n_sample, 4))\n",
    "classifier_network = classifier(base_layers=feature_map_input, input_rois=roi_input, num_rois=128, nb_classes=nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 14, 14, 1024)\n",
      "Tensor(\"strided_slice_258:0\", shape=(10, 14, 14, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out_sample_rois = RoiPoolingConv(pool_size=14, num_rois=samples_rois.shape[0])([feature_map, tf.expand_dims(samples_rois, axis=0)])\n",
    "print(out_sample_rois.shape)\n",
    "print(out_sample_rois[0,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
