{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone of the Network\n",
    "  > RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing ResNet50 Source code\n",
    "(From Actual Keras Implementation of ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, \\\n",
    "    AveragePooling2D, TimeDistributed, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    shortcut = Convolution2D(nb_filter3, (1, 1), strides=strides, name=conv_name_base + '1', trainable=trainable)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_base(input_tensor=None, trainable=False):\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (3, None, None)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "        \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            print(\"Not Keras tensor\")\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            print(\"Keras tensor\")\n",
    "\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    print(x.shape)\n",
    "    x = Convolution2D(64, (7, 7), strides=(2, 2), name='conv1', trainable = trainable)(x)\n",
    "    print(x.shape)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    print(x.shape)\n",
    "    x = Activation('relu')(x)\n",
    "    print(x.shape)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', trainable = trainable)\n",
    "    \n",
    "    print(x.shape)\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', trainable = trainable)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', trainable = trainable)\n",
    "    print(x.shape)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Ratio = $1024/64$ = $16$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding Boxes, Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 1024, 1024\n",
    "subsampling_ratio = 16\n",
    "\n",
    "img = np.zeros((height, width, 3))\n",
    "\n",
    "### Bounding Box Format ####\n",
    "# Origin - top-left corner.\n",
    "# [xmin, ymin, xmaxm, ymax]\n",
    "############################\n",
    "\n",
    "bbox = np.asarray([[20, 40, 400, 100], [400, 800, 800, 1000]], dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Anchor Boxes of Different Scales & Aspect Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0907 20:46:04.731092 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0907 20:46:04.775948 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0907 20:46:04.776964 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0907 20:46:04.776964 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Keras tensor\n",
      "(1, 1030, 1030, 3)\n",
      "(1, 512, 512, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0907 20:46:06.820670 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0907 20:46:06.893477 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 64)\n",
      "(1, 512, 512, 64)\n",
      "(1, 255, 255, 64)\n",
      "(1, 255, 255, 256)\n",
      "(1, 255, 255, 256)\n",
      "(1, 255, 255, 256)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 128, 128, 512)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(1, 64, 64, 1024)\n",
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "feature_map = nn_base(K.expand_dims(K.variable(img), axis=0))\n",
    "print(feature_map.shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n"
     ]
    }
   ],
   "source": [
    "scales = [8, 16, 32]\n",
    "ratios = [0.5, 1, 2]\n",
    "\n",
    "k = len(scales) * len(ratios)\n",
    "feature_map_size = feature_map.shape[1]\n",
    "\n",
    "anchors = np.zeros((k * feature_map_size * feature_map_size, 4))\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchor Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(subsampling_ratio/2, width, subsampling_ratio, dtype = np.int32)\n",
    "\n",
    "anchor_centres = np.zeros((anchors.shape[0], 2))\n",
    "\n",
    "anchor_centres[:, 0] = np.tile(np.repeat(x, k), feature_map_size) #XCOORDINATES\n",
    "anchor_centres[:, 1] = np.repeat(x, k * feature_map_size) #YCOORDINATES\n",
    "\n",
    "\n",
    "##### ANCHOR CENTRES ######\n",
    "# A1,1, A1,2, A1,3 .... A1,K, A2,1, A2,2, ... A2,K, ........ AFEATUREMAP_SIZE*FEATUREMAP_SIZE,K \n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchor Box Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 5 6 7 8 9 9]\n"
     ]
    }
   ],
   "source": [
    "## Checking Numpy Indexing\n",
    "\n",
    "i = np.array([1,2,3])\n",
    "x = np.array([1,2,4,5,5,6,7,8,9,9])\n",
    "y = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "x[i] = y[i]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_box_no = 0\n",
    "for scale in scales:\n",
    "    for ratio in ratios:\n",
    "        w = subsampling_ratio * scale * np.sqrt(ratio)\n",
    "        h = subsampling_ratio * scale * (1/np.sqrt(ratio))\n",
    "        \n",
    "        ### ANCHOR BOX COORDINATES WITH SCALEi, RATIOj###\n",
    "        anchor_coords = np.arange(start_box_no, anchor_centres.shape[0], step = k)\n",
    "        \n",
    "        anchors[anchor_coords, 0] = anchor_centres[anchor_coords, 0] - w/2 # XMIN\n",
    "        anchors[anchor_coords, 2] = anchor_centres[anchor_coords, 0] + w/2 # YMIN\n",
    "        anchors[anchor_coords, 1] = anchor_centres[anchor_coords, 1] - h/2 # XMAX\n",
    "        anchors[anchor_coords, 3] = anchor_centres[anchor_coords, 1] + h/2 # YMAX\n",
    "        \n",
    "        start_box_no += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
      " [ -56.          -56.           72.           72.        ]\n",
      " [ -82.50966799  -37.254834     98.50966799   53.254834  ]\n",
      " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
      " [-120.         -120.          136.          136.        ]\n",
      " [-173.01933598  -82.50966799  189.01933598   98.50966799]\n",
      " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
      " [-248.         -248.          264.          264.        ]\n",
      " [-354.03867197 -173.01933598  370.03867197  189.01933598]]\n"
     ]
    }
   ],
   "source": [
    "print(anchors[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Labels to Anchor Boxes\n",
    "\n",
    "Positive Labels\n",
    "\n",
    "> 1. For a Ground Truth, the anchor with the max IOU.\n",
    "> 2. For an Anchor Box, if it has IOU > 0.7 with any of the ground truths.\n",
    "\n",
    "Negative Labels\n",
    "\n",
    "> If the anchor box has IOU < 0.3 with every ground truth, then its a negative label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(a, b):\n",
    "    \n",
    "    (xa1, ya1, xa2, ya2) = a\n",
    "    (xb1, yb1, xb2, yb2) = b\n",
    "    \n",
    "    ## CALCULATE INTERSECTION, UNION.\n",
    "    \n",
    "    x1 = max(xa1, xb1)\n",
    "    y1 = max(ya1, yb1)\n",
    "    x2 = min(xa2, xb2)\n",
    "    y2 = min(ya2, yb2)\n",
    "    \n",
    "    ## IF INTERSECTION IS ONE POINT, THEN AREA IS ONE PIXEL.\n",
    "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "    area1 = (xa2 - xa1 + 1) * (ya2 - ya1 + 1)\n",
    "    area2 = (xb2 - xb1 + 1) * (yb2 - yb1 + 1)\n",
    "    \n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection/union\n",
    "    \n",
    "    ## UNION = A + B - (A^B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5451683189282869\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "a = [20, 30, 400, 500]\n",
    "b = [30, 40, 300, 400]\n",
    "\n",
    "print(IoU(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out Anchors whose Coordinates lie outside the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[1 2 3 4]\n",
      " [5 0 0 0]\n",
      " [9 8 7 0]]\n",
      "[[1 2 3 4]\n",
      " [9 8 7 0]]\n",
      "[[1 2 3 4]]\n",
      "[ True False  True]\n",
      "[[1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "temp = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 0, 0, 0],\n",
    "    [9, 8, 7, 0]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "## FIRST COLUMN FILTER\n",
    "print(temp[temp[:,0] > 0])\n",
    "temp = temp[temp[:,0] > 0]\n",
    "\n",
    "## SECOND COLUMN FILTER\n",
    "print(temp[temp[:,1] > 0])\n",
    "temp = temp[temp[:,1] > 0]\n",
    "\n",
    "## FOURTH COLUMN FILTER\n",
    "print(temp[temp[:,3] > 0])\n",
    "temp = temp[temp[:,3] > 0]\n",
    "\n",
    "\n",
    "\n",
    "## APPLYING ALL FILTERS TOGETHER\n",
    "temp = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 0, 0, 0],\n",
    "    [9, 8, 7, 0]\n",
    "])\n",
    "\n",
    "print((temp[:,0] > 0) & (temp[:,1] > 0))\n",
    "temp = temp[(temp[:,0] > 0) & (temp[:,1] > 0) & (temp[:,3] > 0)]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n",
      "(18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "temp = anchors\n",
    "print(temp.shape)\n",
    "temp = temp[(temp[:,0] >= 0) & (temp[:,1] >= 0) & (temp[:,2] <= width) & (temp[:,3] <= height)]\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18376\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "## USING NUMPY ##\n",
    "\n",
    "# BRACKETS IMPORTANT #\n",
    "index_inside = np.where(\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    )[0]\n",
    "\n",
    "print(len(index_inside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Valid Anchors: (18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## USING NUMPY INDEXING ##\n",
    "\n",
    "filtered_anchors = anchors[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "]\n",
    "\n",
    "print(\"No. of Valid Anchors: {}\".format(filtered_anchors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is required to label anchor boxes ??\n",
    "> - For each ground truth, find all anchors that have IOU equal to the max IOU. (directly can be labelled positive.)\n",
    "> - Find all anchors that have max IOU with respect to a groud truth. (positive > 0.7, negative < 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18376)\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "ious = np.zeros((bbox.shape[0], filtered_anchors.shape[0]), dtype = np.float64)\n",
    "\n",
    "for i,a in enumerate(bbox):\n",
    "    for j,b in enumerate(filtered_anchors):\n",
    "        ious[i,j] = IoU(a, b)\n",
    "\n",
    "print(ious.shape)\n",
    "print(ious[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[    1 17815]\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.00283193 0.         0.        ]\n",
      "[0.38560272 0.81984166]\n",
      "(15,)\n",
      "(36366,)\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "\n",
    "print(np.argmax(ious, axis=0))\n",
    "print(np.argmax(ious, axis=1))\n",
    "\n",
    "best_groundtruth_for_each_anchor = np.argmax(ious, axis=0)\n",
    "best_anchor_for_each_groundtruth = np.argmax(ious, axis=1)\n",
    "\n",
    "\n",
    "print(ious.max(axis = 0))\n",
    "print(ious.max(axis = 1))\n",
    "\n",
    "\n",
    "\n",
    "## CALCUALTING NO OF ANCHORS WITH IOU > 0.7 ##\n",
    "\n",
    "print(ious[ious > 0.7].shape)\n",
    "print(ious[ious < 0.3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 7]\n",
      "[5 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "## ROUGH WORK ##\n",
    "\n",
    "a = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 5, 6, 7],\n",
    "])\n",
    "\n",
    "## MAX ALONG AXIS 1 ##\n",
    "x = a[np.arange(a.shape[0]),a.argmax(axis = 1)]\n",
    "print(x)\n",
    "\n",
    "## MAX ALONG AXIS 0 ##\n",
    "x = a[a.argmax(axis = 0), np.arange(a.shape[1])]\n",
    "print(x)\n",
    "\n",
    "\n",
    "### BELOW METHOD NOT WORKING OUT ###\n",
    "### GETTING BROADCASTED UNNECESSARILY ###\n",
    "\n",
    "# print(a.argmax(axis = 0))\n",
    "# print(a[[1,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1 17815]\n",
      "[0.38560272 0.81984166]\n",
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17815 17819 17823]\n"
     ]
    }
   ],
   "source": [
    "### CONDITION 1 ###\n",
    "\n",
    "'''\n",
    "What do we need??\n",
    "For each groundtruth, we need anchors with the max IOU.\n",
    "'''\n",
    "\n",
    "## BEST ANCHOR FOR EACH GROUND TRUTH ##\n",
    "gt_best_arg_anchors = ious.argmax(axis = 1)\n",
    "\n",
    "## BEST ANCHOR IOUS ##\n",
    "gt_best_anchors_ious = ious.max(axis = 1)\n",
    "\n",
    "## ANCHORS THAT HAVE IOU EQUAL TO BEST ANCHOR IOU ##\n",
    "gt_best_anchors = np.where(np.isin(ious, gt_best_anchors_ious))[1]\n",
    "\n",
    "'''\n",
    "#### THIS IS NOT WORKING FOR SOME REASON ####\n",
    "## ious[ious == gt_best_anchors_ious] ##\n",
    "#############################################\n",
    "\n",
    "### FOR LOOP METHOD OF OBTAINING ANCHORS EQUAL TO MAX IOU ###\n",
    "### NOT ADVISABLE! USE NUMPY!! ###\n",
    "\n",
    "for i in range(ious.shape[0]):\n",
    "    print(ious[i].shape, gt_best_anchors_ious.shape)\n",
    "    print(np.where(ious[i] == gt_best_anchors_ious[i]))\n",
    "\n",
    "'''\n",
    "\n",
    "print(gt_best_arg_anchors)\n",
    "print(gt_best_anchors_ious)\n",
    "print(gt_best_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0.36675443 0.38560272 0.38560272 ... 0.00283193 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "### CONDITION 2 ###\n",
    "\n",
    "\"\"\"\n",
    "What do we need?\n",
    "For each anchor, find for which ground truth it has highest IOU.\n",
    "\"\"\"\n",
    "\n",
    "anchor_best_arg_gt = ious.argmax(axis = 0)\n",
    "anchor_best_gt_ious = ious.max(axis = 0)\n",
    "\n",
    "\n",
    "### Here we dont have to find which ground truth box the respective anchor has hihgest IOU. ###\n",
    "### Reference Paper says so. ###\n",
    "\n",
    "print(anchor_best_arg_gt)\n",
    "print(anchor_best_gt_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Labels\n",
    "\n",
    "Label Values\n",
    "\n",
    "> - -1 = ignore label\n",
    "> - 1 = positive label\n",
    "> - 0 = negative label\n",
    "\n",
    "\n",
    "IOU Thresholds\n",
    "\n",
    "> - Positive Label = > 0.7\n",
    "> - Negative Label = < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.full((filtered_anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "positive_threshold = 0.7\n",
    "negative_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POSITIVE LABELS ###\n",
    "## CONDITION 1\n",
    "\n",
    "labels[gt_best_anchors] = 1\n",
    "\n",
    "## CONDITION 2\n",
    "\n",
    "labels[anchor_best_gt_ious >= positive_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NGEATIVE LABELS ###\n",
    "\n",
    "labels[anchor_best_gt_ious < negative_threshold] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the RPN\n",
    "> #### Sampling\n",
    "> #### Parameterizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling\n",
    "- Each minibatch comes from one single image.\n",
    "- From that image, we will use 256 anchors as sample.\n",
    "- In each sample, the ratio of positive to negative anchors is $1:1$.\n",
    "- If this is not so, we will make it so by disabling certain anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Ideal Positive Samples: 128.0.\n",
      "No. of Ideal Negative Samples: 128.0.\n"
     ]
    }
   ],
   "source": [
    "sample_size = 256\n",
    "pos_ratio = 0.5\n",
    "\n",
    "pos_size = sample_size * pos_ratio\n",
    "neg_size = sample_size - pos_size\n",
    "\n",
    "\n",
    "print(\"No. of Ideal Positive Samples: {}.\".format(pos_size))\n",
    "print(\"No. of Ideal Negative Samples: {}.\".format(neg_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Positive Labels: 39\n",
      "No. of Negative Labels: 17990\n",
      "No. of Disabled Labels: 347\n"
     ]
    }
   ],
   "source": [
    "pos_labels = labels[labels == 1]\n",
    "neg_labels = labels[labels == 0]\n",
    "disabled_labels = labels[labels == -1]\n",
    "\n",
    "\n",
    "print(\"No. of Positive Labels: {}\".format(len(pos_labels)))\n",
    "print(\"No. of Negative Labels: {}\".format(len(neg_labels)))\n",
    "print(\"No. of Disabled Labels: {}\".format(len(disabled_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17583 17588 17593 17598 17603 17807 17811 17815 17819 17823 17827 17831\n",
      " 18023 18027 18031]\n",
      "[    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    57    59    61    63    65    67    69    71    73    75    77    79\n",
      " 17583 17588 17593 17598 17603 17807 17811 17815 17819 17823 17827 17831\n",
      " 18023 18027 18031]\n"
     ]
    }
   ],
   "source": [
    "## SHORT ROUTE ##\n",
    "print(np.where(labels == 1)[0])\n",
    "\n",
    "## LONG ROUTE ##\n",
    "print(np.where((labels == 1) == True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISABLING ANCHORS ###\n",
    "\n",
    "if len(pos_labels) > pos_size:\n",
    "    pos_indices = np.where(labels == 1)[0]\n",
    "    disabled_indices = np.random.choice(pos_indices, len(pos_labels) - pos_size, replace = False)\n",
    "    labels[disabled_indices] = -1\n",
    "\n",
    "## UPDATE NO. OF POSITIVE LABELS ##\n",
    "pos_size = len(pos_labels)\n",
    "\n",
    "\n",
    "if len(neg_labels) > sample_size - pos_size:\n",
    "    neg_indices = np.where(labels == 0)[0]\n",
    "    disabled_indices = np.random.choice(neg_indices, len(neg_indices) - pos_size, replace = False)\n",
    "    labels[disabled_indices] = -1\n",
    "\n",
    "## UPDATE NO. OF NEGATIVE LABELS ##\n",
    "neg_size = pos_size\n",
    "\n",
    "\n",
    "## RUN PREVIOUS CELL TO SEE THAT NO OF -VE LABELS == +VE LABELS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameterizing Anchor Box Coordiantes\n",
    "\n",
    "> $x' = (x - xa) / wa $ \\\n",
    "$y' = (y - ya) / ha $ \\\n",
    "$w' = log(w/wa) $ \\\n",
    "$h' = log(h/ha) $\n",
    "\n",
    "From this we can see that we need,\n",
    "\n",
    "- groundtruth_box = \\[xc, yc, w, h] for which that anchor has max IOU.\n",
    "\n",
    "\n",
    "We need to format the anchor targets in the same form before parameterizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]\n",
      " ...\n",
      " [ 400  800  800 1000]\n",
      " [  20   40  400  100]\n",
      " [  20   40  400  100]]\n"
     ]
    }
   ],
   "source": [
    "## TAKING ADVANTAGE OF NUMPY BROADCASTING TO GENERATE GT BOXES FOR EACH ANHOR ##\n",
    "\n",
    "anchor_best_gt_boxes_coords = bbox[anchor_best_arg_gt]\n",
    "print(anchor_best_gt_boxes_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104. 120. 136. ... 888. 904. 920.]\n",
      "[ 56.  56.  56. ... 968. 968. 968.]\n",
      "[181.01933598 181.01933598 181.01933598 ... 181.01933598 181.01933598\n",
      " 181.01933598]\n",
      "[90.50966799 90.50966799 90.50966799 ... 90.50966799 90.50966799\n",
      " 90.50966799]\n",
      "(18376,)\n"
     ]
    }
   ],
   "source": [
    "## CALCULATING ANCHOR BOX XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "anchor_w = filtered_anchors[:,2] - filtered_anchors[:,0]\n",
    "anchor_h = filtered_anchors[:,3] - filtered_anchors[:,1]\n",
    "\n",
    "anchor_x_c = filtered_anchors[:,0] + 0.5 * anchor_w\n",
    "anchor_y_c = filtered_anchors[:,1] + 0.5 * anchor_h\n",
    "\n",
    "print(anchor_x_c)\n",
    "print(anchor_y_c)\n",
    "print(anchor_w)\n",
    "print(anchor_h)\n",
    "\n",
    "print(anchor_x_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210. 210. 210. ... 600. 210. 210.]\n",
      "[ 70.  70.  70. ... 900.  70.  70.]\n",
      "[380 380 380 ... 400 380 380]\n",
      "[ 60  60  60 ... 200  60  60]\n",
      "(18376,)\n"
     ]
    }
   ],
   "source": [
    "## CALCULATING GROUND TRUTH XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "gt_w = anchor_best_gt_boxes_coords[:,2] - anchor_best_gt_boxes_coords[:,0]\n",
    "gt_h = anchor_best_gt_boxes_coords[:,3] - anchor_best_gt_boxes_coords[:,1]\n",
    "\n",
    "gt_x_c = anchor_best_gt_boxes_coords[:,0] + 0.5 * gt_w\n",
    "gt_y_c = anchor_best_gt_boxes_coords[:,1] + 0.5 * gt_h\n",
    "\n",
    "print(gt_x_c)\n",
    "print(gt_y_c)\n",
    "print(gt_w)\n",
    "print(gt_h)\n",
    "\n",
    "\n",
    "print(gt_x_c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5855728   0.49718446  0.40879611 ... -1.59099026 -3.83384458\n",
      " -3.92223293]\n",
      "[ 0.15467961  0.15467961  0.15467961 ... -0.75130096 -9.92159202\n",
      " -9.92159202]\n",
      "[0.7415674  0.7415674  0.7415674  ... 0.79286069 0.7415674  0.7415674 ]\n",
      "[-0.41111211 -0.41111211 -0.41111211 ...  0.79286069 -0.41111211\n",
      " -0.41111211]\n"
     ]
    }
   ],
   "source": [
    "## APPLYING ABOVE FORMULA ##\n",
    "\n",
    "t_x = (gt_x_c - anchor_x_c)/anchor_w\n",
    "t_y = (gt_y_c - anchor_y_c)/anchor_h\n",
    "t_w = np.log(gt_w/anchor_w)\n",
    "t_h = np.log(gt_h/anchor_h)\n",
    "\n",
    "print(t_x)\n",
    "print(t_y)\n",
    "print(t_w)\n",
    "print(t_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5855728   0.15467961  0.7415674  -0.41111211]\n",
      " [ 0.49718446  0.15467961  0.7415674  -0.41111211]\n",
      " [ 0.40879611  0.15467961  0.7415674  -0.41111211]\n",
      " ...\n",
      " [-1.59099026 -0.75130096  0.79286069  0.79286069]\n",
      " [-3.83384458 -9.92159202  0.7415674  -0.41111211]\n",
      " [-3.92223293 -9.92159202  0.7415674  -0.41111211]]\n",
      "(18376, 4)\n"
     ]
    }
   ],
   "source": [
    "## CONVERTING TO [XC, YC, W, H] FORMAT ##\n",
    "\n",
    "\n",
    "t_anchors = np.zeros((filtered_anchors.shape[0], 4))\n",
    "t_anchors[:,0] = t_x\n",
    "t_anchors[:,1] = t_y\n",
    "t_anchors[:,2] = t_w\n",
    "t_anchors[:,3] = t_h\n",
    "\n",
    "\n",
    "print(t_anchors)\n",
    "print(t_anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36864, 4)\n",
      "[False False False ... False False False]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. We have calculated the anchors for only valid locations.\n",
    "2. We need to do it for invalid locations as well.\n",
    "\n",
    "And pass the whole thing to the RPN.\n",
    "These are the regression targets.\n",
    "'''\n",
    "\n",
    "anchor_targets = np.zeros((anchors.shape[0], 4))\n",
    "print(anchor_targets.shape)\n",
    "\n",
    "anchor_targets[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "] = t_anchors\n",
    "\n",
    "print( (anchors[:, 0] >= 0) & (anchors[:, 1] >= 0) & (anchors[:, 2] <= width) & (anchors[:, 3] <= height))\n",
    "print(anchor_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n",
      "(39,)\n",
      "(39,)\n",
      "(36786,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We need to prepare the anchor labels.\n",
    "These are the classification targets.\n",
    "'''\n",
    "\n",
    "anchor_labels = np.full((anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "anchor_labels[\n",
    "    (anchors[:, 0] >= 0) &\n",
    "    (anchors[:, 1] >= 0) &\n",
    "    (anchors[:, 2] <= width) &\n",
    "    (anchors[:, 3] <= height)\n",
    "] = labels\n",
    "\n",
    "print(anchor_labels)\n",
    "print(anchor_labels[anchor_labels == 1].shape)\n",
    "print(anchor_labels[anchor_labels == 0].shape)\n",
    "print(anchor_labels[anchor_labels == -1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Architecture\n",
    "\n",
    "> Sliding a network over the feature map.\n",
    "> Use a Conv2D for regression & classification.\n",
    "\n",
    "- Regression No. of Output Channels: 4 * k\n",
    "- Classification No. of Output Channels: k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn(base_layers,num_anchors):\n",
    "    x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "    \n",
    "    x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "    x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
    "    \n",
    "    x_class = Reshape((-1, 1))(x_class)\n",
    "    x_regr = Reshape((-1, 4))(x_regr)\n",
    "    \n",
    "    return [x_class, x_regr, base_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_1/Reshape:0' shape=(1, 36864, 1) dtype=float32>, <tf.Tensor 'reshape_2/Reshape:0' shape=(1, 36864, 4) dtype=float32>, <tf.Tensor 'activation_40/Relu:0' shape=(1, 64, 64, 1024) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(rpn(feature_map, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_scores, pred_reg_scores, base_layers = rpn(feature_map, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_class_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 36864, 1)\n",
      "(1, 36864, 4)\n"
     ]
    }
   ],
   "source": [
    "#### RESHAPING REGRESSION OUTPUT TO [NO_ANCHORS,X,Y,W,H] ####\n",
    "#### RESHAPING CLASSIFICATION OUTPUT TO [NO_ANCHORS, OBJECTNESS_SCORE]\n",
    "\n",
    "print(pred_class_scores.shape)\n",
    "# print(K.reshape(pred_class_scores, (1, -1)).shape)\n",
    "print(pred_reg_scores.shape)\n",
    "# print(K.reshape(pred_reg_scores, (1, -1, 4)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions for RPN\n",
    "\n",
    "1. Classification Loss. (Binary Cross Entropy)\n",
    "2. Regression Loss. (Smooth L1 Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = K.get_value(K.reshape(pred_class_scores, (1, -1))[0])\n",
    "pred_box = K.get_value(K.reshape(pred_reg_scores, (1, -1, 4))[0])\n",
    "\n",
    "print(pred_class[:10])\n",
    "print(pred_box[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.38629436 3.29583687]\n",
      "[1.         3.38629436 6.29583687]\n",
      "[1 4 9]\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ####\n",
    "\n",
    "print(np.multiply([1,2,3], np.log([1, 2, 3])))\n",
    "print(np.add(np.multiply([1,2,3], np.log([1, 2, 3])), [1, 2, 3]))\n",
    "print(np.multiply([1, 2, 3], [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BINARY CROSS ENTROPY ###########\n",
    "\n",
    "def binary_crossentropy(y_pred, y_true):\n",
    "    n = y_true.shape[0]\n",
    "    x = np.multiply(y_true, np.log(y_pred))\n",
    "    xhat = np.multiply((1 - y_true), np.log(1 - y_pred))\n",
    "    return np.sum(x + xhat) * (-1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3862943611198906\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ###\n",
    "#### TESTING BINARY CROSSENTROPY ######\n",
    "\n",
    "pred = np.asarray([0.75, 0.25])\n",
    "true = np.asarray([0, 1])\n",
    "print(binary_crossentropy(y_pred = pred, y_true = true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## SMOOTH L1 LOSS ############\n",
    "\n",
    "def smooth_l1_loss(y_pred, y_true, delta = 1):\n",
    "    x = np.abs(y_pred - y_true)\n",
    "    return np.square(np.sum(x[x <= delta]))*0.5 + np.sum(delta * (x[x > delta] - 0.5 * delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07999999999999996\n"
     ]
    }
   ],
   "source": [
    "### ROUGH WORK ###\n",
    "#### TESTING SMOOTHL1 LOSS #####\n",
    "\n",
    "pred = np.asarray([[1, 2, 3]])\n",
    "true = np.asarray([[1.1, 2, 3.3]])\n",
    "\n",
    "print(smooth_l1_loss(pred, true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO\n",
    "\n",
    "1. Convert all NumPy vectors into Keras Tensors for Loss calculations.\n",
    "2. Define Data Generators.\n",
    "3. Start model training.\n",
    "4. Check the sampling done for loss calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras tensor\n",
      "(?, ?, ?, 3)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 64)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 256)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 512)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "(?, ?, ?, 1024)\n",
      "Tensor(\"activation_80/Relu:0\", shape=(?, ?, ?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape = (None, None, 3))\n",
    "feature_map = nn_base(input, trainable = True)\n",
    "print(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reshape_5_1/Reshape:0\", shape=(?, ?, 1), dtype=float32) Tensor(\"reshape_6/Reshape:0\", shape=(?, ?, 4), dtype=float32) Tensor(\"activation_80/Relu:0\", shape=(?, ?, ?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_class_scores, pred_reg_scores, features = rpn(feature_map, k)\n",
    "print(pred_class_scores, pred_reg_scores, features)\n",
    "# rpn_output = rpn(feature_map, k)\n",
    "# print(rpn_output[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x000002A71868CA08>\n"
     ]
    }
   ],
   "source": [
    "#### USING KERAS FUNCTIONAL API ####\n",
    "\n",
    "model_rpn = Model(input, [pred_class_scores, pred_reg_scores])\n",
    "# model_rpn = Model(input, rpn_output[:2])\n",
    "print(model_rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weights from C:\\Users\\Dyanesh\\Deep Learning\\keras_frcnn\\weights\\resnet50_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "### LOADING WEIGHTS FOR PRETRAINED RESNET ON IMAGENET DATASET ###\n",
    "\n",
    "weights_path = \"C:\\\\Users\\\\Dyanesh\\\\Deep Learning\\\\keras_frcnn\\\\weights\\\\resnet50_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "print(\"Getting weights from {}\".format(weights_path))\n",
    "model_rpn.load_weights(weights_path, by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 1e-5, clipnorm = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_loss_box_reg(y_true, y_pred):\n",
    "#     def smooth_l1_sample():\n",
    "    print(\"Regression Loss\")\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "#     return 0\n",
    "#     K\n",
    "    loss = K.abs(K.sum(y_true) - K.sum(y_pred))\n",
    "    return loss\n",
    "#     return K.placeholder(shape=(1,))\n",
    "#     return smooth_l1_sample\n",
    "\n",
    "HUBER_DELTA = 1\n",
    "def smoothL1(y_true, y_pred):\n",
    "   x   = K.abs(y_true - y_pred)\n",
    "   x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
    "   return  K.sum(x)\n",
    "\n",
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def rpn_loss_cls(y_true, y_pred):\n",
    "#     def binary_crossentropy_sample(y_true, y_pred):\n",
    "    print(\"Classification Loss\")\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    loss = K.abs(K.sum(y_true) - K.sum(y_pred))\n",
    "    return loss\n",
    "#     return K.constant(1)\n",
    "#     return K.placeholder(shape=(1,))\n",
    "#     return binary_crossentropy_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0907 20:48:30.781344 25608 deprecation_wrapper.py:119] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0907 20:48:30.794298 25608 deprecation.py:323] From C:\\Users\\Dyanesh\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls, rpn_loss_box_reg])\n",
    "model_rpn.compile(optimizer=optimizer, loss=[binary_crossentropy, smoothL1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Callbacks=keras.callbacks.ModelCheckpoint(\"./models/rpn/rpn.resnet.weights.{epoch:02d}-{loss:.2f}.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=4)\n",
    "callback=[Callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 3 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 5 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 5 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 5 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 5 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, None, None, 5 4719104     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, None, None, 9 4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, None, None, 3 18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, None, 1)      0           rpn_out_class[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, None, 4)      0           rpn_out_regress[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 13,331,373\n",
      "Trainable params: 13,300,781\n",
      "Non-trainable params: 30,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rpn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "\n",
    "### SAMPLE IMAGE ###\n",
    "\n",
    "data = {}\n",
    "data['img'] = img\n",
    "data['bboxs'] = bbox\n",
    "\n",
    "img_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(bboxs, anchor_scales, anchor_ratios, feature_map_size, subsampling_ratio):\n",
    "    \n",
    "    k = len(anchor_scales) * len(anchor_ratios)\n",
    "    anchors = np.zeros((k * feature_map_size * feature_map_size, 4))\n",
    "    \n",
    "    x = np.arange(subsampling_ratio/2, width, subsampling_ratio, dtype = np.int32)\n",
    "    \n",
    "    ### ANCHOR CENTRES ###\n",
    "    \n",
    "    anchor_centres = np.zeros((anchors.shape[0], 2))\n",
    "    anchor_centres[:, 0] = np.tile(np.repeat(x, k), feature_map_size) #XCOORDINATES\n",
    "    anchor_centres[:, 1] = np.repeat(x, k * feature_map_size) #YCOORDINATES\n",
    "    \n",
    "    ### ANCHOR BOX COORDINATES ###\n",
    "    \n",
    "    start_box_no = 0\n",
    "    for scale in anchor_scales:\n",
    "        for ratio in anchor_ratios:\n",
    "            w = subsampling_ratio * scale * np.sqrt(ratio)\n",
    "            h = subsampling_ratio * scale * (1/np.sqrt(ratio))\n",
    "\n",
    "            ### ANCHOR BOX COORDINATES WITH SCALEi, RATIOj###\n",
    "            anchor_coords = np.arange(start_box_no, anchor_centres.shape[0], step = k)\n",
    "\n",
    "            anchors[anchor_coords, 0] = anchor_centres[anchor_coords, 0] - w/2 # XMIN\n",
    "            anchors[anchor_coords, 2] = anchor_centres[anchor_coords, 0] + w/2 # YMIN\n",
    "            anchors[anchor_coords, 1] = anchor_centres[anchor_coords, 1] - h/2 # XMAX\n",
    "            anchors[anchor_coords, 3] = anchor_centres[anchor_coords, 1] + h/2 # YMAX\n",
    "\n",
    "            start_box_no += 1\n",
    "    \n",
    "    ### REMOVING OUT OF BOX ANCHORS ####\n",
    "    \n",
    "    filtered_anchors = anchors[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ]\n",
    "\n",
    "    ### CALCULATING IOUS ###\n",
    "    ious = np.zeros((bbox.shape[0], filtered_anchors.shape[0]), dtype = np.float64)\n",
    "\n",
    "    for i,a in enumerate(bbox):\n",
    "        for j,b in enumerate(filtered_anchors):\n",
    "            ious[i,j] = IoU(a, b)\n",
    "\n",
    "    ## BEST ANCHOR FOR EACH GROUND TRUTH ##\n",
    "    gt_best_arg_anchors = ious.argmax(axis = 1)\n",
    "\n",
    "    ## BEST ANCHOR IOUS ##\n",
    "    gt_best_anchors_ious = ious.max(axis = 1)\n",
    "\n",
    "    ## ANCHORS THAT HAVE IOU EQUAL TO BEST ANCHOR IOU ##\n",
    "    gt_best_anchors = np.where(np.isin(ious, gt_best_anchors_ious))[1]\n",
    "    \n",
    "    anchor_best_arg_gt = ious.argmax(axis = 0)\n",
    "    anchor_best_gt_ious = ious.max(axis = 0)\n",
    "    \n",
    "    ### LABELS ###\n",
    "    \n",
    "    labels = np.full((filtered_anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "    positive_threshold = 0.7\n",
    "    negative_threshold = 0.3\n",
    "\n",
    "    ### POSITIVE LABELS ###\n",
    "    ## CONDITION 1\n",
    "\n",
    "    labels[gt_best_anchors] = 1\n",
    "\n",
    "    ## CONDITION 2\n",
    "\n",
    "    labels[anchor_best_gt_ious >= positive_threshold] = 1\n",
    "    ### NGEATIVE LABELS ###\n",
    "\n",
    "    labels[anchor_best_gt_ious < negative_threshold] = 0    \n",
    "    \n",
    "    ### SAMPLING ###\n",
    "    \n",
    "    sample_size = 256\n",
    "    pos_ratio = 0.5\n",
    "\n",
    "    pos_size = sample_size * pos_ratio\n",
    "    neg_size = sample_size - pos_size\n",
    "    \n",
    "    pos_labels = labels[labels == 1]\n",
    "    neg_labels = labels[labels == 0]\n",
    "    disabled_labels = labels[labels == -1]\n",
    "    \n",
    "    ### DISABLING ANCHORS ###\n",
    "\n",
    "    if len(pos_labels) > pos_size:\n",
    "        pos_indices = np.where(labels == 1)[0]\n",
    "        disabled_indices = np.random.choice(pos_indices, len(pos_labels) - pos_size, replace = False)\n",
    "        labels[disabled_indices] = -1\n",
    "\n",
    "    ## UPDATE NO. OF POSITIVE LABELS ##\n",
    "    pos_size = len(pos_labels)\n",
    "\n",
    "    if len(neg_labels) > sample_size - pos_size:\n",
    "        neg_indices = np.where(labels == 0)[0]\n",
    "        disabled_indices = np.random.choice(neg_indices, len(neg_indices) - pos_size, replace = False)\n",
    "        labels[disabled_indices] = -1\n",
    "\n",
    "    ## UPDATE NO. OF NEGATIVE LABELS ##\n",
    "    neg_size = pos_size\n",
    "    \n",
    "    anchor_best_gt_boxes_coords = bbox[anchor_best_arg_gt]\n",
    "\n",
    "    ## CALCULATING ANCHOR BOX XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "    anchor_w = filtered_anchors[:,2] - filtered_anchors[:,0]\n",
    "    anchor_h = filtered_anchors[:,3] - filtered_anchors[:,1]\n",
    "\n",
    "    anchor_x_c = filtered_anchors[:,0] + 0.5 * anchor_w\n",
    "    anchor_y_c = filtered_anchors[:,1] + 0.5 * anchor_h\n",
    "    \n",
    "    ## CALCULATING GROUND TRUTH XCENTER, YCENTER, WIDTH, HEIGHT ##\n",
    "\n",
    "    gt_w = anchor_best_gt_boxes_coords[:,2] - anchor_best_gt_boxes_coords[:,0]\n",
    "    gt_h = anchor_best_gt_boxes_coords[:,3] - anchor_best_gt_boxes_coords[:,1]\n",
    "\n",
    "    gt_x_c = anchor_best_gt_boxes_coords[:,0] + 0.5 * gt_w\n",
    "    gt_y_c = anchor_best_gt_boxes_coords[:,1] + 0.5 * gt_h\n",
    "    \n",
    "    ## PARAMETERISING ##\n",
    "\n",
    "    t_x = (gt_x_c - anchor_x_c)/anchor_w\n",
    "    t_y = (gt_y_c - anchor_y_c)/anchor_h\n",
    "    t_w = np.log(gt_w/anchor_w)\n",
    "    t_h = np.log(gt_h/anchor_h)\n",
    "\n",
    "    t_anchors = np.zeros((filtered_anchors.shape[0], 4))\n",
    "    t_anchors[:,0] = t_x\n",
    "    t_anchors[:,1] = t_y\n",
    "    t_anchors[:,2] = t_w\n",
    "    t_anchors[:,3] = t_h\n",
    "    \n",
    "    anchor_targets = np.zeros((anchors.shape[0], 4))\n",
    "\n",
    "    anchor_targets[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ] = t_anchors\n",
    "\n",
    "    anchor_labels = np.full((anchors.shape[0],), fill_value = -1, dtype = np.int32)\n",
    "    anchor_labels[\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= width) &\n",
    "        (anchors[:, 3] <= height)\n",
    "    ] = labels\n",
    "\n",
    "    return anchor_labels, anchor_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(img_data, anchor_scales, anchor_ratios, feature_map_size, subsampling_ratio):\n",
    "    while True:\n",
    "        for data in img_data:\n",
    "            img = np.expand_dims(data['img'], axis = 0)\n",
    "            bboxs= data['bboxs']\n",
    "            anchor_cls_targets, anchor_reg_targets = get_targets(bboxs, anchor_scales, anchor_ratios, feature_map_size=feature_map_size, subsampling_ratio=subsampling_ratio)\n",
    "            print(anchor_cls_targets.shape, anchor_reg_targets.shape, img.shape)\n",
    "            anchor_cls_targets = np.expand_dims(anchor_cls_targets, axis = 0).reshape((1, -1, 1))\n",
    "            anchor_reg_targets = np.expand_dims(anchor_reg_targets, axis = 0).reshape((1, -1, 4))\n",
    "            yield np.copy(img), [np.copy(anchor_cls_targets), np.copy(anchor_reg_targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n",
      "(36864,) (36864, 4) (1, 1024, 1024, 3)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/reshape_6_loss/Mean_2/_3999]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ca431221affe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_rpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_map_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/reshape_6_loss/Mean_2/_3999]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1,255,255,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_141-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "history = model_rpn.fit_generator(train_generator(img_data, scales, ratios, feature_map_size, subsampling_ratio), epochs=1, steps_per_epoch = 1, callbacks=callback)\n",
    "loss_history = history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "> There seems to be an issue in the loss function. This is because the tensors used belong to the Tensorflow Framework. \\\n",
    "To mitigate this, I need to learn how to use those tensors. That's what this section will be about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(12,), dtype=float32)\n",
      "Tensor(\"Reshape_25:0\", shape=(1, 3, 4), dtype=float32)\n",
      "Tensor(\"Reshape_26:0\", shape=(1, 36864, 4), dtype=float32)\n",
      "Predicted Shape = (1, 64, 64, 36)\n",
      "Targets Shape = (1, 36864, 4)\n",
      "Tensor(\"Abs_5:0\", shape=(1, 36864, 4), dtype=float32)\n",
      "(?,)\n",
      "Tensor(\"LessEqual_2:0\", shape=(1, 36864, 4), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "a = K.constant([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "print(a)\n",
    "\n",
    "b = K.reshape(a, (1,-1, 4))\n",
    "print(b)\n",
    "\n",
    "### Predicted.\n",
    "c = K.ones((1, 64, 64, 36))\n",
    "print(K.reshape(c, (1, -1, 4)))\n",
    "\n",
    "\n",
    "### Targets.\n",
    "\n",
    "d = K.ones((1, 36864, 4))\n",
    "\n",
    "\n",
    "print(\"Predicted Shape = {}\".format(c.shape))\n",
    "print(\"Targets Shape = {}\".format(d.shape))\n",
    "\n",
    "\n",
    "###  NOW WE HAVE TO CALCULATE HUBER'S LOSS ###\n",
    "c = K.reshape(c, (1, -1, 4))\n",
    "\n",
    "x = K.abs(c - d)\n",
    "print(x)\n",
    "\n",
    "less_than_delta = K.less_equal(x, 1)\n",
    "print(K.square(x[less_than_delta] * 0.5))\n",
    "\n",
    "print(less_than_delta)\n",
    "\n",
    "# print(c[c < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUBER_DELTA = 1\n",
    "def smoothL1(y_true, y_pred):\n",
    "   x   = K.abs(y_true - y_pred)\n",
    "   x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
    "   return  K.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04999999999999996"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.asarray([1, 2, 3])\n",
    "d = np.asarray([1.1, 2, 3.3])\n",
    "K.eval(smoothL1(c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = K.constant([1, 1, 1e-5, 1, 0, 1, 0, 1], dtype = 'float32')\n",
    "b = K.constant([0.5, 1, 1e-7, 0, 1, 1, 1, 0], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.101784\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(K.mean(K.binary_crossentropy(a,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.6931472,   0.       , -16.118095 ,        -inf,   0.       ,\n",
       "         0.       ,   0.       ,        -inf], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(K.log(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    y_true = K.switch(y_true <= 0, 1e-15, y_true)\n",
    "    y_pred = K.switch(y_pred <= 0, 1e-15, y_pred)\n",
    "#     y_true = K.cast(y_true, 'float32') + 1e-7\n",
    "#     y_pred = K.cast(y_pred, 'float32') + 1e-7\n",
    "    a = y_true * K.log(y_pred)\n",
    "    print(K.eval(a))\n",
    "    b = (1 - y_true) * K.log(1 - y_pred) \n",
    "    print(K.eval(b))\n",
    "#     sum = K.sum(a + b)\n",
    "\n",
    "#     n = K.mean()\n",
    "#     return sum\n",
    "    return -1*K.mean(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-e7a79ff99ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-b20ed44d5e20>\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     y_true = K.cast(y_true, 'float32') + 1e-7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     y_pred = K.cast(y_pred, 'float32') + 1e-7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mswitch\u001b[1;34m(condition, then_expression, else_expression)\u001b[0m\n\u001b[0;32m   3065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melse_expression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3066\u001b[0m             \u001b[0melse_expression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melse_expression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3067\u001b[1;33m         \u001b[0mexpr_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthen_expression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcond_ndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mexpr_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m             raise ValueError('Rank of `condition` should be less than or'\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mndim\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m     \"\"\"\n\u001b[1;32m--> 619\u001b[1;33m     \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "print(K.eval(binary_crossentropy(a, b)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
